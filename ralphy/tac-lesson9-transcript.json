{
  "video_id": "rd-framework-context-window-mastery",
  "url": "https://agenticengineer.com/tactical-agentic-coding/course/rd-framework-context-window-mastery",
  "title": "Elite Context Engineering",
  "channel": "Agentic Engineer",
  "duration": 4200,
  "language": "en",
  "language_name": "English",
  "is_auto_generated": false,
  "extracted_at": "2026-01-14T04:10:50.626Z",
  "transcript": "A focused engineer is\na performant engineer and\na focused agent is\na performant agent. Context\nengineering is the name\nof the game for\nhigh value engineering in\nthe age of agents.\nSo how good are\nyour context engineering skills?\nDo you have a\nskill issue? Let's find\nout and fix it.\nThere are three levels\nof context engineering and\na fourth hidden level\nif you're on the\nbleeding edge pushing into\nagentic engineering. But first\nwe have to ask,\nwhy are context engineering\ntechniques so important? It's\nbecause context engineering enables\nyou to manage the\nprecious and delicate resource\nthat is the context\nwindow of your agents\nlike Claude Code. There\nare only two ways\nto manage your context\nwindow, R and D.\nLet's break down each\ntechnique at each level\nand use the R&D\nframework to maximize not\nwhat you can do,\nbut what your agents\ncan do for you.\nA huge focus in\nTAC is scaling up\nthe intelligence we can\ndeploy both in the\nloop and out the\nloop. But with every\nagent we create, we\nmust adopt their perspective\nto maximize their impact\ncontext is a critical\nin-agent leverage point that\ndetermines how an agent\nperforms at any given\ntask there's a sweet\nspot a range of\ncontext where your agent\nperforms to its maximum\npossible capability for the\ntask at hand as\nyou scale up to\nhundreds and thousands of\nagent executions hitting this\nsweet spot consistently becomes\neven more important and\nwe do that with\ncontext engineering we obsessively\nmanage the context going\nin our agents. We\nadopt our agents perspective\nto gain an awareness\nof the state of\nour agents inside of\nour agentic pipelines, inside\nof our ADWs. When\naligned with the right\nmodel prompt pools and\nthe right range of\ncontext, we can hit\nthe core four bullseye\nover and over and\nover. This directly increases\nour agentic coding KPIs\nwe break down in\ntech and our KPIs\ndirectly tell us if\nwe're improving our agentic\ncoding capabilities. Adding the\nright context to your\nagent is usually the\neasy part. The real\ntrick is finding the\ncontext agentically and then\nremoving and delegating context\nso that it doesn't\nend up creating context\nrot and context bloat.\nSearch and destroy is\nthe real skill in\ncontext engineering, and we\ncan do this better\nthan anyone with the\nR&D framework. When you\nboil it down, there\nare only two ways\nto manage your context\nwindow, R and D.\nreduce and delegate. Every\ntechnique we'll break down\nright now fits into\none or both of\nthese buckets. Let's start\nat the beginner level\nand move up to\nmore technical levels of\ncontext engineering. Your agent's\ncontext window is a\nprecious, renewable, but limited\ntemporal resource. What does\nthat mean? The context\nwindow is ephemeral. It\nresets. It's alive for\nonly a certain amount\nof time and the\nstate in your context\nwindow is critical to\nyour success. Whenever you\nhave a resource that\ndetermines your success, you\nmust measure it so\nyou can improve it.\nThe context window is\nthe single most important\nleverage point for effective\nagentic coding. So how\ndo we measure it?\nInside of the elite\ncontext engineering codebase,\nwe can break down\nhow exactly we'll measure\nour context in our\nClaude Code agents. We\nhave two primary modes\nof measuring context, context\nin our agent and\ncontext we might add\nto our agent. If\nwe spin up a\nClaude Code instance, you\ncan see here we\nhave some context problems\nalready that we'll work\nthrough. You can type\nslash context and see\nall the context in\nour agent's context window.\nThis is your most\nimportant tool for measuring\nand therefore managing your\ncontext window. It shows\nyou exactly how much\nstuff your agent will\nwork through with every\nprompt execution. You can\nsee here we are\nabsolutely torching or clawed\nopus tokens. We have\n63K tokens already spent\non boot up. If\nyou never run slash\ncontext, you will not\nfind this information and\nyou will not know\nthat we've already spent\n31% of our available\ncontext window. Our second\nmechanism for understanding context\nis token counters. In\nthe bottom right of\nmy instance here, you\ncan see I have\na token counter counting\nthe number of tokens\nhighlighted and in the\nfile. We have 2,600\ntokens available in the\nREADME. So anytime our\nagent interacts with the\nREADME, which is a\nhigh touch point for\nagents, they'll consume 2000\ntokens if they read\nthe entire file. Measuring\nyour context is foundational.\nEvery context engineering technique\nwe build from here\ndepends on this. If\nyou aren't actively paying\nattention to the state\nof your agent's context,\nyou're just vibe coding\nand you'll only be\nable to tackle the\nlowest hanging fruit, which\nis already a massively\nsaturated space. To push\nfurther, you must learn\nto see from your\nagent's perspective. What gets\nmeasured gets managed. So\nmeasure your context window.\nUse slash context and\ninstall a tokenizer right\nin your IDE so\nyou know what's coming\ninto your agent's context.\nDo not load MCP\nservers unless you need\nthem. Take a look\nat how much of\nmy Claude Code Opus\ntokens are being chewed\nup by MCP tools.\n24.1 thousand tokens. Okay,\nthis is 12% of\nthe entire available context\nwindow, it's very likely\nyou're wasting tokens with\nMCP servers you're not\nactively using. This is\na simple, easy beginner\ncontext engineering mistake to\nmake. Thankfully, the solution\nis simple. Be very\npurposeful with your MCP\nservers. If we open\nup the directory here,\nyou can see we\nhave a variety of\nMCP servers. Inside of\nthe .mcp.json file, we\nhave a bad practice\nof context engineering inside\nof this codebase.\nWe have a default\n.mcp.json file that is\nalways loading into the\ncontext window of our\nagents. Just for MCP\nservers, it's consuming 24K\ntokens. Let's round down,\nthat's 10% of our\nentire 200K token context\nwindow, chewing up expensive,\nvaluable Claude Opus tokens.\nYou might have a\nmodel in the future,\nregardless of your model,\ncontext management is still\ncritically important. 10K tokens\nis 5% of your\nentire 200K context window.\nThis means 5% less\nwork you can do\nwith this swing of\nyour agent. And if\nyou boot up five\nagents over an hour,\nthat's 25% of a\ncontext window in total,\ncompletely wasted, okay? Unless\nyou're always using every\nsingle MCP server, which\nI highly doubt, okay?\nAs you can see,\nthese numbers will stack\nup against you very\nquickly. The first thing\nI recommend doing is\nget rid of this.mcp.json.\nJust completely delete this\nthing. Okay, don't use\na default.mcp.json for your\ncodebase. All right,\nand why is that?\nIt's because right away\nclears up our context\nwindow, okay? If we\ntype Claude now context,\nwe've just saved some\n20,000 tokens by not\npreloading any MCP servers,\nokay? Do not assume\nyou need these. If\nyou do need these,\nI recommend you fire\nthese up by hand.\nThe cracked Claude Code\nteam at Anthropic has\na couple of quick,\nsimple, easy command line\nflags you can use.\nCloud dash dash MCP\nconfig, and now you\njust pass in the\nconfig you want. So\nlet's say I just\nwanted the Firecrawl MCP\nserver. You can see\nI have this specialized\nfile here that pulls\nin just the Firecrawl\nMCP server, and I've\nself fixed it with\n4K. So I know\nexactly how many tokens\nare going to get\nconsumed by default every\ntime. Okay, so I\ncan copy the path\nto this, paste that\nthere. And if you\ndo have some globals\nthat you wanna overwrite,\nyou can use dash\ndash strict MCP config,\nand then you can\nfire this off and\ncheck this out. When\nwe run slash context,\nwe're only going to\nget that 6K tokens\nstrictly from the Firecrawl\nMCP server. And now\nwe can kick off\nthis specialized agent focused\non just this one\nMCP server, all right?\nAnd if you do\nneed every single MCP\nserver, explicitly reference it,\nbe very conscious with\nthe state going into\nyour context window. There\nare many places to\nbe wasteful as an\nengineer, to move fast\nand break things. The\ncontext window of your\nagents is not one\nof them. Here, we\nare of course using\nthe R in the\nR and D framework.\nWe are reducing. So\nyou might think this\nis not a big\ndeal, but you have\nto think about every\nsingle agent instance you\na claw.md or any\nsimilar auto loading memory\nfile. While this seems\nconvenient at first, it\ncreates problems as you\nscale your agentic coding\nacross different tasks. So\nwhat is context priming?\nand why is it\nsuperior to a memory\nfile? And why is\nit superior to claw.md?\nLet's first double click\ninto claw.md. There's nothing\ninherently wrong with this\nfile. Like most technology,\nit's how it's used\nthat's the problem. If\nwe boot up a\nnew instance here, you\ncan see right away\nwe have this error\nmessage. Let's address this\nnow, okay? We have\nbuilt up a massive,\nand I mean massive,\nclaw.md file. If we\nrun slash context once\nagain and monitor what's\ngoing on here, we\nhave cleaned up our\nMCP servers, but we\nhaven't cleaned up is\nthis massive memory file.\nWe have a 23,000\ntoken memory file, again,\nshowing up about 10%\nof our entire context\nwindow of expensive Opus\ntokens. I'm of course\nexaggerating my claw.md file\nhere just to showcase\nthis idea, but I\ncan almost guarantee you\nthere's an engineer out\nthere somewhere with a\nclaw.md file that is,\nyou know, 3,000 lines\nlong. And why is\nthat? It's because they\nand their team, they've\njust constantly added additional\nitems to their memory\nover and over and\nover again until it's\nbecome what it is\nnow. Okay, a massive\nglob of mess, okay?\nEven the claw code\nengineers built in a\nwarning here for us.\nLarge claw.md will impact\nperformance What they're really\nsaying here is There's\na big chunk of\nstate in the context\nwindow that will likely\nchange the outcome and\ndeter it from the\noutcome you're looking for.\nThe claw.md file is\nincredible for one reason.\nIt's a reusable memory\nfile that's always loaded\ninto your agent's context\nwindow. Simultaneously, a claw.md\nfile is terrible for\nthe exact same reason.\nIt's a reusable memory\nfile that's always loaded\ninto your agent's context\nwindow. So why is\nthat a problem? The\nproblem with always on\ncontext is that It's\nnot dynamic or controllable.\nEngineering work inside of\ncodebases constantly changes,\nbut the claw.md file\nonly grows. Over time,\nas you and your\nteam add more information,\nthe file grows and\ngrows, and eventually it\nbecomes bloated with context\nthat isn't relevant to\nevery engineering task, and\nthis is the key.\nEventually, it's not gonna\nbe relevant for the\nwork you're doing. It's\ngoing to have useless\ncontext in your precious\ncontext window, and in\nthe worst case, it's\ngonna have contradictory information\ninside of your context\nwindow. That is the\nworst possible case, and\nthis will happen if\nyou just keep growing\nyour memory file. All\nright, so what's the\nsolution here? The solution\nis context priming. Let's\ntrim down, right? Let's\nuse this flaw.concise, right?\nIt's a lot simpler.\nIt's something that we\nalways want to add,\nyou know, and take\na look at this,\nright? It's only 43\nlines and it's just\ngot some, you know,\nmock structure for this\ncodebase. And these\nare just some things\nthat we always want\nevery single agent to\nhave, okay? I have\nto keep stressing that\nbecause this is the\nreality of the memory\nfile. It will always\nbe added. So copy\nthis, we'll clean this\nup, save that, resetter\nagent here, CLD is\nan alias. You can\ncheck out all the\naliases I'm gonna run\nthroughout this lesson. At\nthe bottom of the\nreadme, you can see\nall the aliases right\nhere. All right, so\nnow we have a\nconcise MD file. The\nwarning is gone. We\ncan type slash context\nand check this out.\nOur context window on\nboot up on startup\nis looking Much, much\nbetter, 92% free. What's\nleft, right? Our small\nmemory file is down\nto 0.2%, right? 350\ntokens, this is great.\nThis is a clear\nfocus agent. Now, what\ndo we use instead\nof this large memory\nfile? We should context\nprime. What does that\nmean? Let me show\nyou, slash prime, and\nwe hit enter. Context\npriming is when you\nuse a dedicated reusable\nprompt, AKA a custom\nslash command, to set\nup your agent's initial\ncontext window specifically for\nthe task type at\nhand. So with every\ncodebase, I always\nset up Claude commands\nYou can see here\nwe have two prime\ncommands in this code\nbase. Priming is just\na reusable prompt. We\ncan take a look\nat this right here.\nIt's very simple. It\nhas a concise structure\nwhere we have the\npurpose, we have our\nrun step, we have\na read step and\na report step. Okay,\nnow our agent is\nready to go. So\nit's read a couple\nfiles, it's read the\nreadme, it understands the\nstructure of the code\ndifferent areas of focus\nin our codebase.\nOkay, so imagine a\nyou know, prime bug\ncommand, right? For bug\nsmashing, imagine a prime\nchore or prime feature,\nor like we have\nin this codebase,\nprime CC, okay? This\nis a focused prompt.\nIt's our hot loading\nmemory file for operating\nwith Claude code and\nupdating the Claude code\nfiles inside of this\ncodebase, okay? And\nso, you know, you\ncan see it looks\nvery similar. We're actually\nrunning the base prime\ncommand right from the\nprime CC command to\nwhere we're stacking prompts\nto better manage our\ncontext window. And then\nyou can see here,\nwe're just saying read\na couple extra files\nand do the same\nthing, report your understanding\nof the codebase.\nEven with this small\nexample, elite context engineering\ncodebase, there's already\nroom for specialization. Are\nwe working on the\napp level or are\nwe working on the\nClaude agent level, right?\nAnd as you know\nfrom tech, we are\ntalking here whenever we're\nworking on the agents,\nwe're talking about the\nagentic layer, right? We're\nworking on the agentic\nlayer. We're building the\nsystem that builds the\nsystem. So prime, right?\nDon't default. Your claw.md\nfile should be shrunk\nto contain only the\nabsolute universal essentials that\nyou're 100% sure you\nwant loaded 100% of\nthe time. You see\nhow powerful that conditional\nis and how strict\nthat conditional is? So\nbe very careful with\nthese memory files, keep\nthem slim, and instead\nprefer context priming. This\nway you can build\nup many areas of\nfocus for your agents.\nAnd if you find\nyourself coming back to\nsome specific area of\nfocus, build out a\nprime command for that\nspecific area of focus\nfor you and your\nteam. This is the\nbeginning of a big\nagentic level technique that\nwe're gonna talk about\nin this lesson. You\ncan see we have\nthis new experts directory.\nWe'll talk about that\nat the end of\nthis lesson. So now\nwe enter the intermediate\nzone. Let's enter the\nintermediate zone of context\nengineering and talk about\ncontrolling your output tokens.\nOutput tokens are nearly\nalways the most expensive\npart of your agent.\nOutput tokens are priced\nanywhere from three to\nfive X the price\nof your input tokens.\nThat means one right\ncosts you up to\nfive times more output\ntokens burn your compute\nand therefore burn a\nhole in your wallet\nfast. Thankfully, We can\nmicromanage this just a\nlittle bit with output\nstyles to limit and\nspecify the types of\noutput you want Cloud\nCode to have and\ntherefore the number of\noutput tokens CloudCode will\ngenerate when responding. Now\nit's important to note\na lot of the\noutput tokens are chewed\nup when you're actually\nwriting and generating files\nand when CloudCode is\nreturning large chunks back\nto you, there's not\na lot you can\ndo about this, but\nwe can control the\nresponses CloudCode has directly\nto you. Now we\ncan showcase that with\na CloudCode settings file.\nSo inside of our\ndot Claude directory here,\nwe have settings dot\nlocal dot concise. All\nright, so I'm gonna\ncopy the path to\nthis and you can\nsee it has an\noutput style specified, okay?\nIt has a one\nword output style, right?\nSo let's see how\npowerful this can be.\nClaude in Yolo mode\nwith Sonnet, specify a\nsettings file right here\nand kick this off.\nNow we'll just type\nsomething simple here, we'll\njust say hi and\nthen we'll open up\nanother terminal side by\nside and type Claude.\nSo you can see\nhere our agent just\nsaid done. Okay, so\nit's not interested in\ntalking to us. It's\nnot interested in chewing\nup output tokens. Now\nhere on the right\nside, if we type\noutput styles, you can\nsee we're running the\ndefault. And let me\nactually go ahead and\nget this in YOLO\nmode here as well,\nrunning the Sonnet model.\nOutput styles here, we\nhave default. And if\nwe say hi here,\nwe're of course gonna\nget a normal response\ncoming out of cloud\ncode, okay? So right\naway with just a\nhigh, we are getting\na massive difference in\noutput tokens, okay? And\nkeep in mind, these\nare output tokens, right?\nLet's kick this up,\nright? Let me show\nyou the scale in\nthe response of our\none word output style\nversus our default cloud\ncode style they're both\ngoing to do the\nsame work they're both\ngoing to complete and\ngenerate this new file\nright here but the\ndifference and the output\nand the difference and\nthe consumption of tokens\nspecifically the output tokens\nis going to be\nlarger and we can\nlook at this output\nstyle exactly concise done\ncheck this out so\nwe have a you\nknow list here of\noutput styles and you\ncan see here we\nare continuously reiterating this\nclock code output style\nto just say done\nThere are of course\na couple exceptions to\nthis. We don't always\njust want a point\nblank done response. If\nwe ask our agent\na question or something\ngoes wrong, we of\ncourse want a more\nwritten out response. But\nmost of the time\nwhen our agent is\nshipping work successfully, all\nit needs to do\nis respond with done,\nwhich is what we're\ngonna see here in\njust a second. So\nyou can see on\nthe right side, our\nagent has completed and\nit's reported these output\ntokens to us here.\nAnd on the left\nside here, when our\nagent finishes, it's going\nto just report Done.\nIt's not giving us\nany extraneous, extra detail,\nverbose information. We know\nexactly what we asked.\nJust tell us if\nit was successful or\nif it failed. Okay?\nAnd so, you know,\nthis might seem like\na small thing. What\nI want to do\nis just showcase this\nsimple idea so that\nyou can understand at\nscale how important this\nis. Okay? So we'll\npaste this in. And\nof course, we can\nmonitor our token usage.\nWe can see point\nblank, this one response\ncoming out of cloud\ncode consumed 150 output\ntokens, okay? Not too\nbad, right? Now, if\nwe open up a\nnew file and copy\ndone, all right, let's\ncopy just done. And\nwe'll actually put this\non the left and\nwe'll put this on\nthe right. You can\nsee here we have\ntwo tokens, all right?\nSo it's not the\nfact that this is\na ton of tokens,\nit's not, but it's\nthe fact that this\nis two tokens and\nthis is 150 tokens.\nWhen we're running Outlook\nagents, as we start\nto get out the\nloop, we don't need\nto be chewing up\nthis 150 extra tokens\nacross tens of prompts,\nacross hundreds of prompts\nand hundreds of agents,\nokay? Every piece of\ncontext matters. When you\nlook at a graph\nof this stuff, when\nyou start to see\nyour token consumption, you\nknow this to be\ntrue, okay? We have\nreduced our token token\nusage here in this\none element of Cloud\nCode down from 150.\nThis is some massive\n99% reduction in token\nusage, okay? And it's\nall because we are\ncontrolling the output style\nof Claude Code with\na concise done prompt.\nThere are other versions\nof this. You can\nfind some better middle\nground, but you can\nsee very quickly how\nthis is gonna stack\nup and this is\na great way to\nconserve your token usage.\nNow, it's also important\nto note here that\noutput styles do something\ninteresting to the Cloud\nCode instance you're running.\nIt effectively swaps the\noutput style block in\nthe system prompt, right?\nIt hot swaps the\noutput style block in\nthe system prompt of\nClaude Code. This is\nan interesting trend. Keep\nyour eye on this.\nWe're gonna talk about\nthe future of context\nengineering at the end\nof this lesson, some\npotential future directions that\nyou can bet on.\nLet's go ahead and\nclose our agents and\nmove on to a\nbig idea, a popular\nidea in the world\nof Claude Code. Let's\ntalk about sub-agents. Now,\nit's not just about\nusing sub-agents. This is\nabout using sub-agents properly.\nWhen you use Cloud\nCode sub agents, you\nare effectively creating a\npartially forked context window.\nLet's create a cloud\ninstance here. If we\ntype context in an\nagent, a brand new\nagent, you'll notice something\nreally interesting. We have\ncustom agents here. All\nright, we have three\ncustom agents that we\ncan use at any\npoint in time. We\ncan, of course, find\nthese inside of Cloud\nCode. Under the agents\ndirectory, we can look\nat any one of\nthese, right? Now you'll\nnotice something quite interesting.\nAll of our agents\nhere, our custom agents\nonly consume 122 tokens.\nWhereas you can see\nmy rough token counter\nis looking at 900\nfor this one agent.\nWhat's going on here?\nWhat's the big difference?\nThe big difference here\nis that when you're\nworking with sub agents,\nyou are working with\nsystem prompts, okay? There\nis a massive difference\nbetween the system prompt\nand a user prompt,\nright? When you're prompting\nClaude Code, you're writing\nuser prompts when you're\nbuilding reusable custom slash\ncommands, you're writing a\nuser prompt that all\ngets passed right into\nthe agent. This is\na system prompt, which\nis nice because it\nmeans that it's not\ndirectly added to our\nprimary agents context window.\nOkay. And this advantage\nof sub agents continues\nwith clock of sub\nkick off sub agents\nto do this work\nfor us. So our\nprimary agents reading this\nfile and it's gonna\nkick off however many\nagents we need to\nto fetch every one\nof our AI doc\nURLs, right? So it\nlooks like, I don't\nknow, what do we\nhave here, 10 or\n11? You can see\nthis is gonna get\nkicked up here pretty\nsoon after we do\na date check on\nany file here that's\nold than 24 hours,\nwhich I think all\nof them are at\nthis point. And so\nyou can see it's\nremoving these and then\nit's going to fire\nup these agents to\nreload our AI docs.\nThere it is, doc\nscraper. And this is\ncritical, right? A web\nscrape can consume quite\na bit of tokens.\nAnd so we have\nthis load AI docs,\nreusable agentic prompt that's\ngonna kick this off.\nYou can see that\nthe token's starting to\ntick up. We already\nhave 3K for each\nagent. This is 3K\ntokens times eight or\n10 that isn't added\nto our primary agent.\nThis is sub-agent delegation.\nWe're leveraging the context\nwindows of our sub-agents\nto do work and\nkeep it out of\nour primary agent. In\nthis case, this is\na great use case\nfor sub-agents. We have\nthis workflow where Dock\nScraper, You know, we\nhave this system prompt\nhere that details exactly\nhow to web scrape\nwith Firecrawl or Webfetch,\nright? Whatever web scraping\ntool you wanna use,\nit has it here.\nThis would be a\ngood example for us\nto fire up and\nload that one MCP\nserver. But now these\nagents are just going\nto run the scrape,\nwhich will consume their\ncontext window. And then\nthey're going to write\nthe output files, right?\nSo now we should\nsee refreshed AI docs\nwritten here. Yup, there\nthey are. And there\nit is. Yeah, there's\nour success command here.\nWe of course are\nusing a great prompt\nstructure. If we go\nback to load AI\ndocs and collapse here,\nyou can see we're\nusing a classic agentic\nprompt workflow format where\nwe have the purpose,\nvariables, workflow and report\nformat, definitely check out\nthe agentic prompt engineering\nextended lesson to learn\nall of the powerful\nprompt structures you can\nuse inside of both\nyour system prompts and\nyour user prompts like\nthis. This is a\nclassic workflow we use\na lot throughout TAC\nand throughout our extended\nlessons. So you can\nsee here all the\ntokens that were not\nadded to my primary\nagents context window. We\ncan of course slash\ncontext to prove that\nwe're only up to\n9K tokens, okay? We\ndelegated work, right? We're\nstepping into the D\nin the R and\nD framework. There's only\ntwo ways to manage\nyour context window, reduce\ncontext, entering your primary\nagent and delegate context\nto sub-agents and as\nyou'll see in upcoming\ntechniques to other primary\nagents. CloudCo sub-agents have\nlimitations. Sub-agents sit at\nthe intermediate level for\na reason because instead\nof keeping track of\njust one set of\ncontext model prompting tools,\nthe core four, we\nnow have to keep\ntrack of as many\nas you spawn sub-agents.\nSo it becomes super\nimportant to isolate the\nwork that your sub-agents\nare doing into one\nconcise prompt to one\nfocused effort. Remember, a\nfocused agent is a\nperformant agent. Sub-agents are\nalso a little trickier\nbecause of the flow\nof information. The flow\nof information in these\nmulti-agent systems is critical.\nYour primary agent, is\nprompting your sub-agents and\nyour sub-agents are responding\nnot to you but\nback to your primary\nagent. So once we\nstart getting into this\nintermediate, advanced, and agentic\nlevel, we have to\nkeep track of every\nagent's core four that\nwe spin up. If\nyou're losing track of\na single agent, right,\nand you have a\nbunch of wasted context,\nyou probably aren't yet\nready for sub-agents. You\nprobably want to spend\nsome more time cleaning\nup, managing, and maintaining\nclean context windows for\nyour existing single primary\nagent. But once you're\nready, sub agents are\na great intermediate level,\na great intermediate technique\nto step into because\nyou can delegate the\nentire context window to\none or more sub\nagents. As you saw\nhere, we say probably\n40,000 total tokens and\nran all this work\nmuch faster than it\nwould have taken a\nsingle primary agent. So\nnext up, we have\na powerful classic pattern.\nWe're continuing to push\ninto the delegation side\nof the R&D framework.\nYou can have two\nagents working side by\nside. One agent plans,\nthe other agent executes\nthe plan. You have\na planner and a\nbuilder, an architect and\nan editor. This is\na classic prompt chaining\ntechnique that expands and\nextrapolates very well into\nthe age of agents\nwith your Claude Code\nagents and with any\nagent. We have a\nreusable prompt in this\nsmall reusable codebase\ninside of our application\nlayer. So app slash\nCCTS wrapper. Okay, so\nlet's fire that off\nthis agent. is only\ngoing to plan. And\nnow, as you can\nimagine, if our agent\non the left is\nonly planning, we have\na completely free context\nwindow on the right\nto build. Okay. And\nso we of course\nhave slash build. We\ncan then take this\nbuild command and execute\nit on the plan\ngenerated by our plan\nagent. So we're going\nto let this agent\ncook. And as you\ncan see, we are\ncontinuing to reduce context\nwindows and delegate work\nbetween agents. The idea\nhere is simple. Separate\nyour agents responsibilities. Why?\nBecause especially for your\nimplementer, AKA your editor\nand builder agent, you\nwant their context focused\nso they can make\nsurgical perfect error free\nedits. A lot of\nengineers are stacking up\na chat window. They're\nprompt chaining inside of\na single agents chat\nwindow over and over\nand over. And they're\nnot realizing that they're\ncausing context rot and\ncontext bloat with every\nprompt that isn't laser\nfocused to the task\nat hand. With our\nplanning prompt, we have\na detailed prompt in\nour classic instruction prompt\nformat. Again, check out\na Genetic Prompt Engineering\nextended lesson on the\npowerful prompt structures that\nyou can write. And\nwe're being very, very\nclear about what it\nneeds to do. We're\nplanning work. and we're\nplanning work with a\npowerful Opus agent. Again,\nif you're in the\nfuture, I hope you\nhave better, more powerful\nmodels, use that. These\ntechniques are all the\nsame across models. Don't\nget stuck up on\nany one individual model,\nbut you can see\nhere our planner has\nfinished planning. Now we\ncan just copy this\nand we can be\nvery confident that whatever\nis in here is\nup to par with\nour standards because we've\nput upfront investment into\nour planning phase. So\nI can just copy\nthe reference to this\nand go to our\nbuild agent, paste this\nin, and with no\ncontext priming at all,\neverything the build agent\nneeds is inside of\nthis plan. It's all\nthere because our planner\ntook care of that\nfor the builder, all\nright? reducing context and\nwe're delegating context, right?\nYou can see our\nplanner has consumed some\n7k tokens here. We're\nin a very small\ncodebase. And just\nimagine that this is,\nyou know, a larger\ntask, right? 60,000 tokens,\nwhatever. You can be\nguaranteed that the tokens\nused to plan, not\nall of that is\ncritical for the building.\nAnd this makes sense.\nWhen you're engineering, when\nyou're writing plans, you\nalways go overboard. By\nthe end of your\nplanning phase, you should\nbe deleting information that\nisn't relevant to the\nwork you want done.\nYou should go overboard,\nthen delete. Here we\nhave the R&D framework\nin full swing. We're\ndelegating across two agents\nto reduce context when\nit matters most. There\nare a lot of\nplaces where it matters,\nbut when your agent\nis actually writing the\ncode, when they're actually\nrunning your agentic workflows,\nthat's when it matters\nthe most. And this\ncontext window here that's\ndoing all this writing,\nright, chewing up our\nexpensive output tokens, it's\na focused agent with\na focused context window,\nand that means it\nis a performant agent.\nAll right, and just\nto detail that prompt\na little bit more,\nif we run up\na little bit, here's\nwhat this agent is\nplanning, just to give\na little bit of\nmore additional context here,\nright? Quite simple, so\nquick plan, and then\nhere's the prompt that\nwe're actually executing. Read\nTypeScript SDK, create reusable,\nthree file wrapper system\nfor calling agents via\nClaude Code, TypeScript SDK.\nHere are some methods,\ntypes file, low level,\nCLI file, create this\nin this directory. All\nright, so just a\nsimple kind of high\nmid-level prompt and our\nbuilder has finished implementing.\nWe can just open\nup this directory and\nwe can see exactly\nwhat was created. There's\nour hello calls and\nthen inside of this\ndirectory, you can see\nhere we have a\nfull on application built\nout. We can of\ncourse, TD apps, CC,\nbun run tab. There's\neverything our bun ecosystem\nis giving us. we\ncan just run, run\ndev, looks like a\nmedia prompt, hello, enter,\nand now the Cloud\nCode SDK via TypeScript\nis running. There's the\nresponse session ID, fantastic,\nthere we go. So\nsimple prompt, simple planner,\nbuilder workflow, architect, editor,\ndelegating across two context\nwindows. Let's take our\nbuilder and let's run\na very well-meaning feature\ninside of Cloud Code.\nA very powerful, useful\nfeature slash compact. Okay,\nso you've probably used\nthis one, but there's\na huge problem with\nthis command. After compact\nruns, do you know\nexactly what's in your\ncontext window every single\ntime? Now, the answer\nsee it is summarizing.\ndecently here. Usually it\nhas some type of\nread file command where\nit automatically read some\nadditional files, right? You\nknow, you can understand\nwhy they did this.\nThe context window is\nlimited. They're facing the\nsame limitations as you\nand I, and they\nwant to provide solutions\nfor them. But just\nlike your prompts, the\ncontext window of your\nagents should not be\nhanded off to any\ntool or team. The\ncompact command for what\nit's worth is great,\nbut it's a bandaid\nfix for the true\nproblem. The context window\nhas grown large and\ncannot fit any additional\ninformation. Instead of compacting,\ninstead of running slash\ncompact, I recommend you\nrun slash clear. Blow\naway the context window\ncompletely. Now if we\nrun slash context, we\nare running a fresh\nfocused agent. Now reset\nwith slash prime, right?\nRun whatever prime command\nyou're running and refocus\non your task at\nhand, right? Build back\nup to where you\nwere and continue forward.\nI know this one\ndoesn't sound great. It's\nlike the first advanced\ntechnique, basically just saying\ndo more work. Don't\ndepend on the slash\ncompact command. Why do\nwe do this? It's\nbecause this way you\nknow exactly what's in\nyour context window and\nyou get in the\nhabit of building tasks\nspecific context priming prompts,\nall right? Just like\nour beginner techniques adjust.\nThese techniques stack up\non each other very,\nvery quickly. The big\nidea here is you\ndon't wanna delegate the\ncontrol of your context\nwindow, all right? This\nis a dangerous game\nto play. You want\nto own this just\nlike you wanna control\nyour prompt or your\nmodel, the context window\nis the same. This\nis also important for\nOutloop agent decoding, right?\nIt prepares you for\nOutloop agent decoding. And\nfor this to work\nat high levels across\nhundreds of agent executions,\nyou need specialized agents\nyou know what the\ncontext will be if\na compact command runs\nyou can't know this\nwith high confidence for\noutloop agent decoding no\nsingle agent should overflow\ntheir 200k tokens and\ntrigger a compact if\nit does you should\nchop up the task\nyou shouldn't need slash\ncompact and if you\nneed to you should\nreset and prime now\nwe can push this\nidea a little bit\nfurther and try to\ndo what the compact\nwindow command is doing\nourselves with our next\nadvanced context engineering technique.\nNotice that with each\ntechnique from beginner to\nintermediate to advanced and\nsoon agentic, we're doing\nR and D, reduce\nand delegate. We're keeping\ntrack of our context\nwindow at all times\nand we're not outsourcing\nit. If you wanna\nscale your agents, monitoring\nand managing the state\nof your context window\nis critical for your\nsuccess, all right? Just\nlike context priming, you\ncan push in loop\nactive context management even\nfurther with context bundles.\nOkay. So with Cloud\nCode hooks, you can\nhook into a couple\nof tool calls to\ncreate a trail of\nwork that you can\nuse to reprime your\nagents for the next\nrun, right? So you\ncan chain together agents\nafter the context window\nhas exploded. So the\ngreat part here is\nwe've been using context\nbundles the entire time.\nSo let's collapse everything\nand open up agents\nand so agents is\nbecoming a additional agentic\nlayer directory where you\ncan just put output\nfrom operations of your\nagents. You can see\nwe have background and\nwe have context bundles.\nLet's click into bundles\nand let's see what\nwe have in this\ndirectory. All right, so\nif we click this\nbundle, we have something\nsuper simple. We have\nslash prime and we\nhave read. If we\nclick into this context\nbundle, you can see\nwe have our quick\nplan. So this was\nthe work that happened\ninside of our planner.\nIt read the file\nas specified and then\nit wrote this plan\nhere for us, right?\nAnd we have the\ntool input and we\nhave a couple of\nother things, right? This\nis powerful. This is\na context bundle. What\nwe have here is\na simple append only\nlog of the work\nthat our Claude Code\ninstances are doing. These\nare unique based on\nthe day and the\nhour and the session\nID, okay? So how\ndoes this work exactly?\nFire up a YOLO\ndangerous mode instance and\nwe just type prime,\nright? Let's just rerun\na prime and let's\nprime our Claude Code,\nright? So we're running\nour prime command around\nClaude Code and you\ncan see this context\nbundle was generated, okay?\nSo there's the prompt\nand let's just pay\nattention to what this\ndoes, all right? We\nhave read commands, we\nhave search commands. Our\nread commands are all\ngetting appended piece by\npiece and what this\ndoes is it gives\nus a solid understanding\nof 60, 70, percent\nof what our previous\nagents have done okay\nand so why is\nthis important this is\nimportant because it tells\na fuller story for\nsubsequent agents to execute\nthere's a bunch of\nadditional read commands and\nthis now, great, who\ncares? Let's open up\na new Claude Code\ninstance. And let's say\nthat this, you know,\nthis agent's context window\nexploded. We can, with\nthis context bundle, run\nslash load bundle, copy\nthe path, paste it,\nhit enter. This agent\nis now going to\nget the full story\nof the previous agent.\nIt's gonna deduplicate any\nread commands. And then\nit's going to create\nan understanding of the\nwork done up till\nthis point. Okay, and\nso imagine this is\nmuch larger, right? Let's\nsay that it's something\nlike, you know, 50\nplus lines of reads\nand writes. We can\nuse a context bundle\nto get a much\nmore accurate replay of\nwhat the previous agent\nwas trying to do.\nYou can see here\nin the summary message,\nvery concisely, the previous\nagent executed this command\nand loaded key findings.\nThat's it, nine files.\nYou can imagine this\ngetting a lot more\ncomplicated with reads, writes,\nand additional prompts, but\nwith this simple pattern,\nwith this session ID,\ngetting tracked here inside\nof this context bundle.\nWe're saving a concise\nexecution log, thanks to\nClaude Code Hooks that\nwe can reference in\nsubsequent agents. And the\ngreat part here is\nof course you can\nconditionally use this. A\nlot of the times\nyou won't need to\nreload the entire context\nbundle because it won't\nbe relevant. But if\nwe needed to, we\ncould get the entire\nreplay of the agent\nup to the point\nin which the context\noverloaded without all of\nthe rights and without\nall the details of\nall the reads. The\ntrimmed down version is\nsuper important, right? We're\nnot recording every operation.\nIf we do that,\nwe'll just end up\noverflowing the next agent's\ncontext window. Okay. So\nyou do have to\nuse this selectively, but\nthis gets us 70%\nof where the previous\nagent was. It gets\nus mounted and restarted\nvery quickly. This is\nanother advanced contact engineering\ntechnique you can use.\nCheck out this code\nbase for the details\non how exactly this\nworks. Our last advanced\ntechnique is simple. It's\na simple idea, it's\na beautiful idea, continues\nto build on the\ntechniques we've worked up\nto use one agent\nfor one purpose. Maybe\nyou've picked up on\nthis with some of\nthe repeat themes that\nwe're getting into, but\nthere's no better way\nto control and manage\nyour context window than\nto ship one thing\nat a time. A\nfocus agent is a\nperformant agent. This advanced\ntechnique forces you to\nsit down and answer\nthe question, what does\nthe pipeline of agents\nlook like for this\nwork? Okay. Once you\nstart doing this well,\nand you understand the\nidea of using one\nagent for one purpose,\nif you've taken tack\nlesson six, you know\nthe full version of\nthis, but once you\nstart doing this well,\nyou'll start engineering and\nproblem solving in this\ntwo-step workflow. First, you\nplan out the work\nyou want done without\nregard for technology. Okay.\nYou'll focus on just\nsolving the problem for\nyour users, for your\ncustomers, right? Always remember,\nYour users and customers\ncome first. The technology\nwe use is a\nmeans to this end.\nThen you'll plan out\nhow you'll delegate your\nwork across several agents,\nforming an agentic pipeline,\nalso known as an\nAI developer workflow, the\nhighest level of agentic\ncoding leverage as discussed\nin TAC. We'll move\non from this big\nidea since it's the\nkey idea in TAC\nLesson 6, but this\nis a massive way\nto manage your context\nwindows. This idea takes\nagent delegation to its\nnatural, most valuable limit.\nUse one agent for\none purpose so that\nyour context windows are\nfocused. A focused agent\nis a performant agent.\nNow we've reached the\nagentic level. Here you've\nmastered all the previous\nlevels of context engineering.\nThis is where things\nget powerful and dangerous\nif you don't know\nwhat you're doing because\nyour patterns will start\nto scale into the\nagentic workflows, into the\nADWs, into the pipelines\nthat you built. Okay.\nSo let's focus on\nthe system prompt. You\ncan massively control Claude\nCode's behavior and really\nany agent's behavior. This\ncan completely change how\nthe tool works even\nmore than Output Styles\nbecause we can control\nand start to overwrite\nthe default Claude Code\nbehavior. I'll say it\npoint blank, many engineers\nwill not get to\nthis level. Many engineers\ndon't need this level,\nokay? But if you're\npushing to the edge,\nthe system prompt gives\nyou even more control\nover your agent and\ntherefore the context flowing\nin and out of\nyour agent. If you\nstart down the path\nof agentic engineering, at\nsome point, you will\nneed to crack open\nand modify the system\nprompt. This is how\nat least not at\nthe time of filming,\nokay? You have to\nrun this in print\nmode, in programmatic mode.\nThis is where we\nstart pushing out the\nloop. So we do\nneed this dash dash\nprint or just dash\nP flag. And then\nwe run a prompt.\nSo I'll say, what\nis Claude.large.md for and\nso that was the\nlarge you know context\nfile that we demoed\nin the beginning 18\n000 tokens massive then\ni'm going to paste\nin this system prompt\nand so check this\nout important when using\nthe read tool always\nread in increments of\n100 lines for example\nand then i give\nan example being really\ndetailed with how to\ncall this tool exactly\nand then if you\nread enough to accomplish\nthe request a task\nstop reading and proceed\nwith the task if\nyou need more information\nread another hundred lines\nand determine if that's\nenough. And then we\nhave one more instruction,\nimportant, we're tapping into\nan information tense keyword.\nWhen you respond to\nthe user with your\nfinal message, always prefix\nyour last message with\ncheck or X for\nsuccess or failure, all\nright? And so this\nagent has been modified,\nright? We have modified\nthe system prompt, we\nare controlling this agent\nat a lower, more\nfoundational level. Okay. The\nsystem prompt really lets\nyou start controlling how\nyour agent behaves and\nwhen you control the\nbehavior, you control the\ncontext window. So let's\nmake sure I end\nthe quote here and\nlet's fire this off.\nYou can see here,\nwe have a concise\nresponse demonstrates what not\nto do with project\ndocumentation intentionally bloated using\nanti-pattern of over contextualization,\ncramming excessive details, blah,\nblah, blah. Okay. So\nit understood it ran.\nThe interesting part here\nis how it ran.\nIf we open up\nour context bundle and\nwe go to this\ncontext bundle that just\nran you can see\nsomething really powerful Okay,\nwhat is this file\nfor? You can see\nour prompt and you\ncan see the subsequent\nreads. Read 100, read\n100. This agent is\nobeying the specific instructions\nin our system prompt.\nWe're saying read 100\nlines at a time.\nIf you have enough\ninformation, stop executing and\nrespond, right? Proceed with\nthe task. This is\nsuper, super powerful. We've\njust reduced the number\nof lines our agent\nhad to read with\nthe read tool, okay?\nAnd we forced Cloud\nCode to increment. This\nis super powerful. And\nthis is just one\nsimple way, one simple\ncontrol mechanism for steering\nthis agent in a\ncompletely different direction. You\ncan push this even\nfurther using the Cloud\nCode SDK. In addition\nto the append system\nprompt command, there is\nalso a SDK specific\ncustom system prompt variable\nthat you can pass\ninto the SDK. Do\nnot use that unless\nyou know what you're\ndoing. The Claude Code\nteam has put a\nton of work into\ncrafting the system prompt\nbe a top tier\nagent for engineering. If\nyou use, I think\nit's called a custom\nsystem prompt, I'll of\ncourse link all the\ndocumentation below in your\nloot box. But if\nyou use this variable,\nyou will blow away\nthe system prompt, use\nthis with caution. Okay.\nAnd so we can\nrun another one. So\nwe have another prompt\nhere, same deal. We're\nreading in chunks of\n100. Figure out what\nClaude Code hooks are\navailable and their respective\ninput schemas from the\ndocumentation. Okay. So I'm\ngonna fire this off.\nHere's that context bundle\nrunning and you can\nsee that same deal.\nThere's all the response\nformats for every hook\nbased on the existing\ndocumentation and there's the\navailable hooks. But you\ncan see here again\nin the context bundle,\nwe're saving the actual\nread executions and the\ntool input. We've overwritten\nthe calling mechanism for\nreading files. You can\nsee there that same\npattern, reading 100 at\na time of the\nClaude Code Hooks directory,\nFor this one, it\nneeded to read more\nto accomplish this task,\nso it did. I\nrecommend you only use\nthis agentic level context\nengineering technique when nothing\nelse works or when\nyou start building your\ncustom agents for your\ndomain specific use cases\nand when you start\ndeploying agents inside of\nyour codebase. Check\nout the agentic horizon\nextended lesson on cloud\ncode SDK mastery. There\nwe break down the\nClaude Code SDK so\nthat you can run\nthis in a more\nprogrammatic way so you\ncan build out specific\nlevel we can kick\noff primary agents through\nprompts, through wrapper CLIs,\nthrough MCP servers, and\nthrough UIs. You've likely\nseen a lot of\nClaude Code management systems\nand a lot of\nagent systems get built\nup into their own\nUIs. That is primary\nagent delegation. Now, what's\nthe most lightweight version\nof multi-agent delegation. You\ncan use ASAP and\nget value out of\nASAP. It's a simple\nreusable custom slash command.\nIf you remember inside\nof the cloud directory\nin our commands directory,\nwe have background.md. This\nis a simple single\nprompt that boots up\na background Claude Code\ninstance. This is the\nsimplest, quickest way, other\nthan going right through\nthe CLI, to delegate\nwork to agents. When\nyou use a pattern\nlike this, we're pushing\nin to powerful Outloop\nagent decoding by running\na single prompt with\na single agent that\ndoes one thing, reports\nits work, and then\nit finishes. So let\nme show you exactly\nwhat I mean. I'll\nrun Claude Opus in\nYolo mode here, and\nthen I'll say slash\nbackground. And you can\nsee here, this fires\noff a full Claude\ncode instance in the\nbackground. Here's our argument\nhint, prompt model report\nfile. I wanna kick\noff the creation of\na plan. There's no\nreason for me to\nsit here in the\nloop prompting back and\nforth when I can\nkick off a background\nagent, when I can\ndelegate this work outside\nof my primary agent's\ncontent context window, right?\nWe're delegating this work\nout. I can open\nup some quotes here,\npaste this in, and\nthis is going to\nkick off a new\nquick plan. So we're\nrunning that plan workflow,\nthat plan agentic prompt\nagain. This time we're\nbuilding out a cloud\ncode. These are just\nrandom code examples. We're\ngoing to read a\ncouple of pieces of\ndocumentation and this time\nwe're building out a\nastral UV Claude Code,\nPython SDK with that\nsame format, right? Those\nthree files by Dantic\ntypes, low level files,\nCLI file, right? Specifying\nwhere to create it.\nThis is the plan.\nLet's fire it off.\nThis is going to\nkick off a background\nagent. Okay. And so\nyou can see our\nprimary agent getting to\nwork here based on\nthe contents of this\nprompt. We can of\ncourse see that, you\nknow, consistent prompt format\nwhere you're reusing great\nprompt structures that get\nwork done for us.\nAgain, check out, the\nagentic prompt engineering, agentic\nhorizon extended lesson to\nlearn how to write\ngreat prompts for the\nage of agents. And\nit's all inside of\nthe workflow step here,\nright? So create the\nagents background directory. We\nhave our default values.\nAnd then this is\nimportant, we're creating a\nreport file, okay? And\nthen we have this\nprimary agent delegation, XML\nwrapper, where we're detailing\na bunch of information\nfor our agent, okay?\nWe are kicking off\na Claude Code instance\nfrom Claude Code. We\nhave compute orchestrating compute,\nagents orchestrating agents, okay?\nThis is where everything\nis headed. Better agents\nand then more agents.\nOnce you master a\nsingle context window, you\ncan scale it up.\nThere's a format here,\nblah, blah, blah, skip\nto the bottom. But\nthe important thing here\nis that this free\nup the primary cloud\ncode instance. You can\nsee we have a\nbackground task, background cloud\ncode kicked off. If\nwe open this up,\nthis is the file\nthat our agent is\ngoing to be reporting\nto. And so cool\nthing here, we can\nopen up a context\nbundle for this agent,\nright? So if we\nhit up here, you\ncan see that exact\nprompt background slash quick\nplan, read, blah, blah,\nblah, blah, blah. This\nagent is starting to\nwork, all right? It's\nstarting to create this\nplan. And we can\nsee that with the\ncontext bundle. You can\nsee this is super\nuseful adding logging, having\nthese trails, there's the\nactual plan just got\nwritten there. Having this\ntrail, this story of\nwhat your agents have\ndone is an important\nagentic pattern. We are\nbuilding up on every\ncontext engineering technique we've\nused thus far. This\nagent should report back\nto its report file\nhere. This is a\ngreat way to track\nthe progress of your\nagents as they work\nin the background. So\nyou can see here,\nwe still have that\none background task running.\nWe should get an\nupdate here. Our agent\nhas, there we go.\nSo you can see\nit's reading its background\nfile now. And then\nsoon it's gonna put\nthe right in here.\nWe should see this\ncome in live as\nour background. delegated agent\ninstance is just writing\nthis plan for us.\nThere's no reason for\nme to sit in\nthe loop. I know\nexactly what this does.\nAnd here is the\noutput. Check this out,\nprogress task completed. It\nrenamed this file. I\nhave an instruction to\nrename the file when\nit finishes, 1302.53. We\ncan click this. It\nis now complete. A\nvery quick one prompt\nagent delegation system It's\nall here for you\nin this codebase.\nThink of these as\nstarting points for understanding\nthem. Don't take my\nword for this. Ignore\nme as well, but\ninvestigate the optimist in\nthe space. See what\nthey can really do.\nSee what we're really\ndoing here. We have\nbackground, compute, agents calling\nagents. We have the\nR&D framework, 12 context\nengineering techniques. These are\nconcrete things. Maybe a\ncouple of these techniques\nfly over your head\nor you're not interested\nor you think it\ndoesn't apply to you.\nThat's fine. Just take\none. a couple of\nthese and improve your\ncontext engineering. The background\nagent task and multi-agent\ndelegation is super important\nbecause it gets you\nout the loop. This\nis a big idea\nwe discuss in TAC\nand it extends into\ncontext engineering. Get out\nthe loop, set up\nmany focused agents that\ndo one thing extraordinarily\nwell. In a lot\nof ways, multi-agent delegation\nis just like sub-agents,\nbut we get complete\ncontrol. We're firing off\ntop-level primary agents from\nour in-loop primary agent\nhere. Okay, so there's\na lot more control\nhere. This background agent\nand the prompt that\nI passed in, right?\nWe can just paste\nthis prompt. I could\nhave asked for anything\nhere, right? This doesn't\nneed to be a\nquick plan. I could\nhave asked for a\nmulti-agent workflow running sub-agents,\nright? There's just so\nmany ways to build\nand to use multi-agent\nsystems. The key idea\nhere is, let's bring\nit all back to\ncontext engineering. The key\nidea here is you\ncan delegate specialized work\nand focus agents by\nbuilding out some type\nof primary agent delegation\nworkflow you can see\nhere in just one\nprompt we have a\nfull Claude Code instance\nin the background doing\nwork for us that\nwe know we don't\nneed to monitor anymore\nand the more you\nbecome comfortable and the\nmore your agentic engineering\nskill improves the more\nyou can stop babysitting\nevery single agent instance\nokay this is a\nbig theme in tech\nwe want to scale\nfrom in loop to\nOutloop to ZTE. Speaking\nof specialization, speaking of\nall these big ideas,\nlet's wrap up with\npotentially one of the\nmost powerful context engineering\ntechniques. Let's talk about\nagent experts. So what\ndoes this all build\nup to? We've already,\ncovered the main idea,\nright? Build focused agents,\ndeploy them in ADWs\nwith specialized pipelines, protect\nyour context window at\nall costs inside of\nevery agent. But once\nyou put all this\ntogether, you can get\nsomething really special, something\nreally powerful. There's not\nreally a name for\nthis yet, but I've\nbeen just blatantly calling\nthis pattern agent experts.\nThe idea is simple\nand powerful, especially for\ncontext engineering with agents\non large codebases.\nOkay, this idea is\nechoed inside of TAC\nwith templates. You can\nuse your agent delegation\nof choice. You can\nuse your primary agent,\nprimary delegated agent, or\nsub-agent. And the whole\nidea is that you\nfire off specialized agents\nthat are experts at\nspecific parts of your\ncodebase. And here's\nthe kicker, you have\nthem auto update their\nown knowledge. This is\nthe agent experts technique.\nLet me show you\nexactly how. Inside of\nour Claude commands directory\nhere, we have an\nexperts directory. Right now\nwe have a single\nexpert in this code\nbase and you can\nsee this agent expert\nis focused on Claude\ncode hooks. Now, before\nwe move forward, let\nme just kick off\nthis expert. So I'm\ngonna run this prompt\nand I'll just paste\nthis in for brevity.\nI'll type slash experts.\nAnd so now we\ncan just see all\nof our experts and\nI want our planning\nClaude code hook expert.\nAnd now we'll paste\nin a prompt. Okay,\nso I'm gonna paste\nthis in. This is\na simple high to\nmid-level prompt, We want\nour expert to take\nthe wheel on this,\nall right? So what\ndoes this do? Long\nstory short here is,\nyou can pause the\nvideo and read it\nif you want. We're\ngonna create a output\nstructure. So we have\nagents, hook logs for\nevery Claude Code instance.\nWe want a full\nlog of every event\nso we can improve\nour agentic coding, right?\nWe want additional monitoring.\nSo how are we\ngonna do that? We're\ngonna have our Cloud\nthe agent that runs\nthis prompt, as you\ncan imagine, is gonna\nbe specialized to running\nClaude Code hooks, right?\nYou can even see\ndirectory structure all the\nrelevant files to this\nspecific piece of our\ncodebase right you\ncan see here we're\nbuilding experts we're not\nbuilding random one-off agents\nrandom agent instances we've\nbuilt a reasonable prompt\nthat mounts and you\nknow to echo all\nthe way back to\nour beginner techniques we\nare in a way\npriming this agent to\nbe an expert at\nthis area of focus\nokay a lot of\nthe work i do\nis aimed at showing\nyou the vision and\ngiving you the new\nbeliefs and the new\nideas, the new context\nthat you need to\ndeploy agents, to deploy\ngenerative AI in new\nforward leaning ways. Okay,\nso this is just\none idea, but you\ncan imagine multiple experts\nacross your codebase\nthat are extraordinary. They're\nlike the engineer on\nyour team that knows\nthat one piece of\ncode, that one feature\nbetter than anyone. Now\nyou can encode this,\nyou can template it\ninto an expert, agent\nexpert and here's the\ncherry on top after\nyou implement the plan\nafter you have your\nexpert build it right\nspecialize at building this\nspecific type of work\nyou can run your\nmeta improvement expert okay\nyou're a Claude Code\nhook expert specialize in\ncontinuous improvement you'll analyze\nthe work done blah\nblah blah and update\nyour plan and build\nexperts so we have\na prompt built improve\nour prompts. Okay, we're\nvery close to the\nedge here. And you\ncan see where this\ngoes for you, right?\nIt's auto documenting itself\nimproving. Let's go ahead\nand continue this workflow.\nYou can see here\nour spec got created,\nyou know, we have\na great spec here\ndetailing exactly how this\nworks. Feel free to\npause at any point.\nAnd I'll go ahead\nand just commit this\nwork with the elite\ncontext engineering codebase\nso that this feature\nwill be built out\nwill be logging this\nstructure by the time\nyou get your hands\non this. All right,\nI'm going to copy\nthe reference to this,\nI'm going to a\nOf course, I'm not\ngonna use this existing\ncontext window if we\ntype slash context. Already\nspent 26K, even though\nwe could chain on\ntop of this agent,\nwe are not. We\nare practicing, we're preparing\nfor Outloop agents. We're\nthinking about this as\nif we're building a\npipeline of agents. I'm\ngonna open a new\ninstance here, Claude, Yolo\nmode, Opus, and then\nI'm gonna type slash\nexpert. We're going to\nbuild this feature and\nthen we're gonna paste\nin the path and\nlet this fresh focused\nagent cook, okay? We\nhave one agent planning,\nwe have the other\nbuilding, and we have\nthe last self improving.\nWhatever changes we make\nto this system, our\nimprove expert, our sub\nprompt, our sub agent\ninside of this three\nstep expert is going\nto look back at\nthe changes made and\nupdate the plan and\nthe build to have\nthe details of the\nimplementation. The planner thinks\nabout what needs to\nbe done and then\nits context window is\ngone, right? We don't\nneed it anymore. The\nbuilder takes the plan\nand actually implements it,\nright? This is a\nclassic pattern. Big shout\nout to the legacy\nAI coding tools, the\nold school tools, Ader,\nand all the other\ntools that separated planning\nand building. This is\na pattern that is\ngoing to continue across.\nAnd as you saw\nin TAC, this pattern\ncan continue and expand\nacross the software developer\nlifecycle. Here's our new\nhook logger getting built\nout, CHMOD. It has\neverything it needs you\ndeploy this into single\nfile scripts, right? It\nhas the information, it\nis an expert. I've\nbuilt an expert set\nhave this feature built\nout exactly as specified.\nOkay, so there's the\nstart session JSONL. We\ncan type hi, we're\ngonna get whatever the\nuser prompts submit, and\nthen we're gonna get\nsome flows coming in.\nahead and run, right?\nWe got a stop\ncommand. Let's go ahead\nand run prime. This\nis going to run\na series of operations,\nright? Let's go ahead\nand kick that off.\nAnd then you're going\nto see the logs\ncome in. That was\nbuilt perfectly in one\nshot with a planner\nand a builder as\nan expert, right? These\nare agent experts. Let's\nrun the final step\nand let's talk about\nthe future of context\nengineering. Okay. So we're\ngoing to run this\nnew Claude Code instance\nin YOLO mode. You\ncan see that log\ngot appended there. Our\nagents, right? In our\nsystem, our agentic system\nis keeping track of\nall types things now\nlog hooks context bundles\nwe can fire off\nbackground agents if we\nwant um but all\nwe want to do\nnow is expert improve\nokay no params We\njust improve and it\ndoes this by looking\nat the git diff.\nIt looks at any\nchanges and then it\nmakes the improvement to\nour existing build and\nplan Claude Code hook\nexpert in our code\nbase. Okay, so you're\ngonna see these changes\nhere flow in. You\ncan see our expert\nis preparing, it's priming\nitself to improve what's\nbeen done. It's gonna\nrun a git status\nin a second here\nand see any relevant\nchanges that are relevant\nspecifically for the files\nit has detailed and\nyou can check out\nthe prompts of course\nin this codebase,\nclassic, great agentic prompt\nengineering in all of\nour prompts here. But\nyou can see it's\ndoing this work and\nit's going to self\nimprove. There we go.\nI've identified several changes\nrelevant learnings, relevant changes\nfrom the universal log\nimplementation. That looks great.\nIf your codebase\nis large or you\nhave a highly technical\narea that requires your\nexpertise or another engineers\non your team, you\nknow, I highly recommend\nusing the agent experts\npattern. Of course, you'll\nhave to maintain and\nmonitor your expert, but\nthis is much better\nthan having it stuck\nin your head or\nan engineer's head, right?\nYou want your agentic\nlayer operating your code\nbase and you operate\nthe agentic layer, right?\nYou know this. If\nyou've taken TAC, we\nbuild the system that\nbuilds the system. Our\nimproving meta agent expert\nis now updating based\non the Git status,\nright? Based on the\nGit, you know, Git\nexecution run. It's updating\nour build and plan.\nAnd here's the summary\nof what was changed,\nright? It just added\na couple sections to\nthe expertise section. So\nwe have a dedicated\nsection inside of both\nour plan and our\nbuild dedicated to specific\nexpertise that gets updated\non the fly. It's\ndedicated, it's differentiated. We\ndon't want this to\nbe in the workflow\nor in the purpose\nor in the instructions.\nWe have a dedicated\nsection built for this.\nWe're following great agentic\nprompt engineering. We're not\nconflating our headers. We're\nnot conflating our sections.\nIt's very important. And\nthis pattern, the agent\nexperts, It brings us\nright back to the\nhighest leverage point of\nagent decoding, the ADW,\nthe AI developer workflow.\nYou can imagine a\nworkflow in ADW where\nwe string together these\nthree prompts in three\nindividual agents. plan, build,\npass the plan to\nthe build, and then\nimprove, and then we\nrun our git commits\nafter, right? This is\nan entire workflow. All\nwe do is pass\nin some prompt, a\nhigh-level prompt that we\nwant, and then this\nworkflow, this specialized agent\ntakes it from there,\nokay? There are many\ndirections to go with\nthis. You can imagine\na router agent that\ntakes in any high-level\nprompt and then determines\nwhat expert to run.\nThere are many ways\nand directions to take\nthis, but I wanna\nleave that up to\nyou, take these 12\ntechniques and apply them,\nget value out of\nthese techniques. All right,\nyes, it takes some\ntime. Yes, you have\nto invest. This is\nnot vibe coding, okay?\nIf it's easy, a\nvibe coder is probably\ndoing it and that\nisn't irreplaceable, okay? That\nis replaceable work. Even\none of these can\nsave you massive time,\nbut you have 12\nhere. Pick one, pick\na couple, dive into\nthem, deploy it into\nyour agentic coding to\nimprove your context engineering.\ncompact problem. Right next\nto that and very,\nvery closely related, we\nare likely to see\nbetter context windows coming\nout of these big\nlabs. Language models, they\ntend to lose massive\ncapability as the context\nsize grows. This is\nan attention mechanism problem\ninside of modern agents.\nYou can plan and\nbet on big labs\nfocusing on better effective\ncontext windows. Okay, another\nbig idea Here is\nhot swapped context windows,\nhot swapping tools, hot\nswapping context in general,\nright? Hot swapping the\nsystem prompt like cloud\ncodes, output styles enable\nus to do, right?\nYou can overwrite and\ntherefore hot swapping existing\nsystem prompt. This is\nan important, interesting pattern.\nImagine for every piece\nof context, user prompts,\nassistant prompts, tool calls,\nsystem. You can swap\nin and out different\ncontexts, right? You can\ndelete context to free\nup the context window,\nokay? Hot swapping context\nis a big idea\nwe're likely gonna see,\nokay? The last two\nare very obvious. You\ncan see these if\nyou're on the edge,\nyou're already doing this\nand you're using TAC\nto help you get\nthere faster, quicker, better.\nMulti-agent architectures for agent\ndelegation. Okay, we touched\non this several times\nthroughout TAC and here\nwe use sub-agents and\nprimary agent delegation. Okay,\nand then lastly, a\nbig trend you can\nbet on, specialized agents\neverywhere. On the bleeding\nedge, you plug into\nthe Claude Code SDK\nand other agent SDKs\nand you specialize every\nelement of the context,\nthe model, the prompt,\nthe tools solve and\ndeliver unique experiences for\nyour users and for\nyour customers. Okay. What's\nbetter than a prompt?\nA prompt chain. What's\nbetter than a prompt\nchain? An agent. What's\nbetter than an agent?\nMany focused, specialized agents\nthat deliver value for\nyou, for your team,\nand most importantly, for\nyour customers and users.\nDon't miss this trend.\nYou now have everything\nyou need to win\nand ship with focused,\nsingle-purposed agents. So all\nthese techniques are us\nbattling with the fact\nthat there are key\nscaling laws and algorithms\ninside of these language\nmodels, inside of generative\nAI that decreases performance\nas context window grows.\nWhat does that mean?\nIt means you can\nsafely bet on spending\nyour engineering time, energy,\nand resources on investing\nin great context management,\nin great context engineering.\nIt's a safe bet\nto bet on context\nengineering. With all the\nfocus on context, let's\nnot forget about prompt\nengineering and specifically agentic\nprompt engineering. If you're\nwriting bad prompts, your\ncontext doesn't matter. If\nyou can't communicate what\nyou want done with\nyour agents when you're\ndelegating when you're reducing\ncontext, you're going to\nbe massively limited and\nyou're going to be\nshooting yourself in the\nfoot, wasting money, right?\nIf you want to\nwrite the best prompts\nand preserve your context\nwindow, you want to\nbe stacking up these\nbig ideas. You'll get\na ton of value\nout of the agentic\nprompt engineering extended lesson\nI've built out for\nthis very purpose. That\nagentic horizon lesson is\ndedicated purely to agentic\nprompt engineering in the\nage of agents. We'll\nbe optimizing prompts for\nClaude Code, but really\nall agent decoding tools.\nWe're betting on the\nwinner and we're preparing\nfor competitors. And of\ncourse, if you wanna\nbuild specialized agents, check\nout the Claude Code\nSDK Mastery. You wanna\nbe using the Cloud\nCode SDK and agent\nSDKs to solve your\ndomain specific problem better\nthan any chat interface\nor any prompt or\nany generic Claude Code\ninstance can, all right?\nSo check out Cloud\nCode Mastery extended lesson\nto build your own\ncustom agents. Fantastic work\nhere. There is a\nlot to digest. This\nlesson is going to\nbe here for you.\nThank you for trusting\nme. Keep in mind,\na focused agent is\na performant agent. I'll\nsee you in TAC\nand I'll see you\nin the next Agentic\nHorizon lesson.",
  "summary": "This lesson covers the R&D Framework for context window mastery. A focused agent is a performant agent, and the context window is your agents most precious resource - ephemeral, limited, and critical to success. There are only two ways to manage context: R (Reduce) and D (Delegate). The lesson covers four levels of context engineering: Level 1 (Measure - use /context command and token counters), Level 2 (Reduce - context priming over CLAUDE.md, compact files), Level 3 (Delegate - sub-agents, worktrees, headless execution), and Level 4 (Self-Improving Experts - agents that update their own plans). Key techniques include context priming (loading only relevant context), the three-step expert pattern (Plan, Build, Improve), and delegating work to isolated sub-agents with fresh context windows.",
  "key_concepts": "1. R&D FRAMEWORK: The only two ways to manage your context window - R (Reduce) and D (Delegate). Master these to maximize agent performance.\n\n2. CONTEXT WINDOW IS PRECIOUS: Your agents most valuable resource is ephemeral, limited, and critical to success. A focused agent is a performant agent.\n\n3. LEVEL 1 - MEASURE: Use /context command to see token usage. Use token counters to understand file sizes. You cannot manage what you do not measure.\n\n4. LEVEL 2 - REDUCE: Context priming over CLAUDE.md. Load only relevant context for the task. Keep files compact. Avoid bloated memory files that consume 10%+ of context on boot.\n\n5. CONTEXT PRIMING: Superior to auto-loading memory files. Selectively prime your agent with only the context needed for the specific task at hand.\n\n6. LEVEL 3 - DELEGATE: Use sub-agents with fresh context windows. Delegate work to isolated environments (worktrees). Run headless executions for parallel processing.\n\n7. LEVEL 4 - SELF-IMPROVING EXPERTS: Agents that update their own plans based on implementation results. The bleeding edge of agentic engineering.\n\n8. THREE-STEP EXPERT PATTERN: Plan (think about what needs to be done), Build (implement it), Improve (look back and update based on changes). Each step can have isolated context.\n\n9. CONTEXT POLLUTION: Too much context confuses agents. Big CLAUDE.md files, excessive memory, irrelevant files all degrade performance. Minimize context to maximize focus.\n\n10. TOKEN AWARENESS: Monitor token consumption constantly. 63K tokens on boot means 31% context already used. Every file read consumes tokens - be intentional about what your agent sees."
}