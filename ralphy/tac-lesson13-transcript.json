{
  "video_id": "agent-experts",
  "url": "https://agenticengineer.com/tactical-agentic-coding/course/agent-experts",
  "title": "Agent Experts: Finally, Agents That Actually Learn",
  "channel": "Agentic Engineer",
  "duration": 3600,
  "language": "en",
  "language_name": "English",
  "is_auto_generated": false,
  "extracted_at": "2026-01-14T04:22:57.740Z",
  "transcript": "This will likely be\nthe most controversial lesson\nof Agentic Horizon. There\nwill be three buckets\nof engineers that watch\nthis lesson. Those who\ndismiss this idea, those\nwho give it a\nshot, and those who\nsay, this is what\nI've been looking for.\nAgents of today have\nmany problems. Most of\nthem can be solved\nwith great context engineering\nand great agentic prompt\nengineering. But there is\none massive problem that\npersists no matter how\ngreat your context engineering\nor agentic prompt engineering\nbecomes. Traditional software improves\nas it's used, storing\nuser analytics, usage data,\nand patterns that create\nalgorithms. Agents of today\ndon't. The massive problem\nwith agents is this.\nYour agents forget. And\nthat means your agents\ndon't learn. There are\na few solutions, but\neach has their own\nproblems. Memory files are\nglobal forced context that\nalways loads. As you\nknow, expertise requires breaking\nrules when the time\nis right. Memory files\nalso must be manually\nupdated, consuming your time\nor your team's time.\nThen we have prime\nprompts, sub-agents, and skills,\npowerful agentic tools. But\nagain, these all have\nto be manually updated\nwhen you wanna add\nnew information and steer\nyour agents in a\ndifferent direction. So, what\nif you could take\nthe best tool for\nthe job of engineering\nagents to the next\nlevel by teaching your\nagents to act, learn,\nand reuse its expertise\nat runtime? What if\nyou could create agent\nexperts? The difference between\na generic agent and\nan agent expert is\nsimple. One executes and\nforgets, the other executes\nand learns. In this\nlesson, I'll execute and\nyou'll learn to build\nagents that turn actions\ninto expertise, automatically storing\nthe right information and\nreusing it with no\nhuman in the loop.\nThis is key. This\nis what makes an\nexpert an expert. You\ndon't need to tell\nan expert to learn.\nIt's in their DNA.\nAlso, real experts don't\nrelearn their craft every\ntime they have a\nnew task. True experts\nare always learning. They're\nupdating their mental model.\nThis mental model is\nsimply put a data\nstructure that evolves over\ntime. With each useful\naction, experts accumulate information,\nexamples, and ultimately expertise\naround a specific topic.\ntopic. This is key.\nYou're not trying to\nsolve every problem. You're\ntrying to solve the\none that matters the\nmost to you, your\nbusiness, and your customers.\nIf this sounds familiar,\nit should. You and\neveryone you admire has\na strong mental model\naround a specific domain\ndown to individual problems.\nThis mental model is\na data structure that\nhelps you solve problems\nbetter and faster as\nyou act, learn, and\nreuse that expertise. So\nin the world of\nAgentic Coding, prompt engineering\nand context engineering, what\nis an agent expert\nexactly? The agent expert\nis a concrete form\nof a self improving\ntemplate meta prompt. That's\na mouthful. Let's break\nthis down because if\nyou understand meta prompts,\nyou will understand agent\nexperts. Meta prompts are\nprompts that build other\nprompts. Template meta prompts\nare prompts that build\nother prompts with a\nspecific purpose and structure.\nThis is a key\nleverage point of agentic\ncoding we discussed in\nlesson three of Tactical\nAgentic Coding. This is\nhow you teach your\nagents to operate and\nbuild as you do.\nNow, self-improving prompts updates\nitself, related prompts, or\nan isolated file with\nnew information that will\nbe used during your\nagent's next execution. When\nwe put it all\ntogether, you get a\nself-improving template metaprompt. If\nthat doesn't make sense,\ndon't worry. We're gonna\nwalk through it step\nby step in this\nlesson. There are people\nwho are proficient. There\nare engineers who are\ngreat, but experts are\nin their own class\nabove the rest because\nthey never stop learning.\nExperts grow. They update\ntheir knowledge about their\ndomain. The expert understands\nthat the game they're\noperating in never ends\nexcept for one condition.\nthe moment they stop\nlearning. I don't know\nabout you, but I\ncertainly want experts operating\nmy codebase and\nproducts, not generic agents\nthat forget that you\nhave to boot up\nover and over and\nmanage the memory files\nof manually. That's the\nfocus of this lesson,\nagent experts. In this\nlesson, we'll walk through\nmeta agentics or put\nplainly, no fancy language,\nmeta prompts, meta sub\nagents and meta skills.\nWe're gonna do this\nto showcase the atoms\nof what makes up\nthe agent expert. We'll\nuse our orchestrator agent\nfrom lesson four to\nshowcase agent experts that\noperate specific areas of\nyour small to large\ncodebase extraordinarily well.\nThis is one of\nthe killer use cases\nof an expert. We'll\nthen take a look\nat a product-focused agent\nexpert that let you\nbuild adaptive user experiences,\na whole new on\ntap type of UI\nUX waiting to be\nunlocked by engineers like\nyou are willing to\npush the boundaries of\nagents. Let's start with\nmeta-agentics, the building blocks\nfor not just your\nagent expert, but your\nentire agentic layer. At\ntheir core, meta agentics\nhelp you build elements\nof the system that\nbuilds the system. As\nmentioned, these include your\nmeta prompts, your meta\nagents, and your meta\nskills. It's important we\ntouch on these because\nthey greatly increase your\noutput as an agentic\nengineer. with or without\nagent experts. Let's run\nthrough each to showcase\ntheir value proposition. In\nthis agent experts code\nbase, you'll have access\nto in your loop\nbox below. We'll start\nwith our meta prompt\nand we'll have it\ncreate a new version\nof a question prompt\ncalled question with mermaid\ndiagrams. We'll fire that\noff. Let's fire off\nthe meta agent, the\nagent that builds the\nagent. We're gonna have\nit create a new\nplanner agent that directly\nreads and executes the\nplan prompt. This way\nwe can scale up\nplanning to multiple agents\nin parallel. And finally,\nwe'll use the meta\nskill to create a\nstart orchestrator skill that's\ngonna kick off the\nfront end and the\nback end of our\nmulti-agent orchestration application that\nwe covered in lesson\nfour. Meta agentics are\ncritical because they let\nyou build more of\nyour agentic layer faster.\nWe have prompts writing\nprompts, agents building agents,\nand skills building skills.\nThere is no code\nbase I create that\ndoes not have meta\nagentics. Every codebase\nmust have meta agentics.\nLet's just be a\nreminder to always use\nand have a stack\nof these ready to\ngo to help you\nbuild out the next\nthing. They serve as\nthe foundation to quickly\nspinning up new agentic\nlayers, which will be\nthe topic of discussion\nand the final agentic\nhorizon lesson. We have\nour question with mermaid\ndiagrams built up here.\nYou can see in\nour classic agentic prompt\nformat, we have a\ngreat structure here and\nour variables just takes\nin the user question\nand then based Based\non the purpose, you\ncan see exactly what's\nhappening here. The key\nis if we search\nmermaid, you can see\nthat we are always\ngonna create mermaid diagrams\nthat enhance understanding. We\nhave a powerful question\nprompt that was built\nout by our meta\nprompt. We then had\nour meta agent build\nout a new planner\nagent. It takes in,\nright, it simply reads\nstart to look more\nlike an expert operating\nyour codebase. So\nif we look at\nour dot claw directory\nand we go into\nour commands where our\nprompts are stored, we\nhave this experts directory.\nWe have a database\nexpert. Let's click into\nthis and understand the\ntwo prompts and this\nnew expertise file. Let's\nopen these up. And\nbefore we deep dive\ninto this, let's execute\na question to our\ndatabase agent. We'll type\nslash question and you\ncan see our question\nprompts here. We'll tab\non database question and\nthen we'll ask this.\ndoes information flow between\nour database tables write\nyour report in this\ntemp file so the\nfirst thing this agent\ndoes is critical and\nit changes the flow\nof everything it first\nreads this expertise file\nnow what is this\nthe expertise file is\nthe mental model of\nthe problem space for\nyour agent expert you\ncan see it first\nread the expertise file\nand then it started\ncomparing its understanding against\nthe actual code. And\nit did it instantly.\nIt didn't need to\ngo search or find\nthese files. It knew\nwhere they were. This\nis the differentiated factor\nof an agent expert.\nIt contains a working\nmental model, just like\nyou or I, or\nany engineer on your\nteam would. This is\nbig. Okay. What we've\ndeveloped here inside this\nYAML file, right? That\ncould be any data\ntype. This is in\nfact, a mental model.\nmodel. Now, it's super\nimportant to just touch\non this idea right\naway. You know, a\nlot of legit engineers\nmight be thinking this,\nisn't that another source\nof truth? Don't we\nnow have the code,\nthe comments, you know,\nthe PRDs, the plans,\nproduct documentation, and this\nexpertise file? This is\nnot what that is.\nLet me be all\ntoo clear about this.\nThis is not a\nsource of truth, okay?\nJust like the mental\nmodel you have of\nyour codebases, right,\nof your products and\ncodebases, all the\ntools that you operate.\nYou don't have a\nsource of truth in\nyour mind. You have\na working memory file.\nYou have a mental\nmodel, a data structure\nthat you constantly update\nwhen you need to\ndive into a specific\nproblem, a specific area,\na specific domain inside\nyour codebase. All\nright. This is what\nthis is. This is\nnot a duplicate. This\nis your agent's mental\nmodel. We can see\nthat it has created\na comprehensive flow of\nour database. Let's open\nthis up. Let's go\ninto our preview view\nhere for this markdown\nfile database information flow\nreport. To be super\nclear, we are pointing\nour agent toward the\nmulti-agent orchestration application. This\ncould be anything, all\nright? System uses six\nPostgres database tables to\ntrack orchestrator agent command,\ntheir communications and logging.\nWe have a parent-child\npattern that cascades deletes.\nAll right, so we\nhave an entity relationship\ndiagram there, great breakdown.\nYou can see all\nthe tables, how they\nrelate. We have information\nflow patterns. We have\nthree-way communication between the\nuser, right? URI, the\norchestrator, and they respond\nback to the user,\nbut also they can\ntalk and communicate to\nthe agent, and then\nthe agent responds to\nthe orchestrator. This isn't\nabout the multi-agent orchestration\nsystem. We're just pointing\nour agents at this\ndomain. All right, so\nthere's a ton of\ndetails here. The key\nhere is this. We\nhad an agent. very\nquickly use its mental\nmodel. It validated its\nmental model against the\nsource of truth. The\ntrue source of truth\nis always the code.\nYou and I know\nthat. Not the comments,\nnot the documentation, not\nthe plans. It is\nthe code. The code\nis what runs and\nbuilds the product. But\nthat does not mean\nthat auxiliary documents and\nmemory and mental models,\nright, expertise, it does\nnot mean that they're\nnot all true valuable.\nAnd you're gonna see\nthat over and over\nagain here. What does\nthis look like? What\nis in this expertise\nfile? And before we\nget there, just to\nat a very high\nlevel, break down the\nquestion prompt, you've taken\nan argument and our\nquestion prompt also has\na static variable that\nreferences, of course, the\nexpertise file. And the\nfirst thing it does\nis it reads this,\nall right? And the\nworkflow, it reads this\nright away. And then\nit validates its assumptions\nagainst the codebase,\nall right? Super critical\nline, I have it\nin here twice, for\nthat reason, all right?\nOnly then does it\nactually report. So that's\nthe question prompt. Now,\nwhat is the expertise\nand how do we\nbuild it? So if\nwe just collapse this,\nyou can see here,\nthis is just a\nhigh level map of\nthe understanding our agent\nhas built up of\nusing. Lightweight pydantic models\nover SQL queries, no\nheavy ORM. Okay, so\nvery interesting here, right?\nWe're starting to define\nthe high level, just\nlike you or I\nwould, right? Oh yeah,\nand that codebase,\nwe're using Postgres, we\nuse Pydantic models, we\nuse raw queries there\ninstead of going for\nan ORM, kind of\ninteresting. And then we\nhave some idempotent SQL\nmigrations, okay? So pay\nattention to how close\nthis is gonna feel\nto your understanding of\nsome of the code\nyou operate in, all\nright? Core implementation, what's\nin this? Let's go\nahead and collapse this\na little bit. Database\nmodule, okay? So that's\nwhere the database is.\nWe have a connection\npool, interesting. We have\nthe purpose of that\nfile, all right? That's\nthe purpose of that\nspecific unit of code,\nperfect. Query patterns, right?\nWe use RAR SQL\nparameter substitution. Uh-oh, Pydantic\nmodels, we use JSNP\nhandling with dumps, okay?\nInteresting. Data models, okay?\nModels, features, interesting, right?\nIt's just kind of\ndefining the table as\nit is, right? What's\nthe agent log? It's\nthe agent logs table,\nduh. obviously, right? So\nwe have this distribution\nfile that when it\nruns, it syncs to\nanother location and there's\nthe script that does\nit. Okay, interesting. We\nhave a way to\ndistribute the data models\nacross many applications. Oh,\nwe also have schema\nmigrations, right? So notice\nwhat's happening here, right?\nWe don't need to\ngo through this whole\nthing. This is a\nmental model. It's not\na source of truth,\nokay? You can think\nof this and all\nreally, you know, all\nsecondary, tertiary pieces of\ninformation about a code\nbase or about a\ncore product All of\nit is a rough\napproximation of what's truly\nthere, right? Of what's\ntruly in the code.\nYou have a mental\nmodel, your team has\na mental model, give\nyour agents a mental\nmodel by giving them\nan expertise file, right?\nNow, how do we\nbuild this? We of\ncourse built this with\nthe self-improve prompt. Now,\nwhat is in this?\nLet's start from the\ntop, right? You maintain\nthe database systems expertise\naccuracy by comparing the\nexisting file against the\nactual codebase implementation.\nAgain, I wanna be\nsuper clear here, I'm\ncommunicating this to my\nagents. This is not\na source of truth.\nThis is not documentation\nabout something. This is\na, we're getting to\nit in a second\nhere, follow the workflow\nto detect and remedy\nany differences, missing pieces\nor outdated information, ensuring\nthe expertise files remains\na powerful mental model\nand accurate memory reference\nfor database related tasks.\nThis self-improve prompt is\ngoing to keep the\nmental model synced. Let's\njust run this self-improve\ndatabase. We have a\ncouple additional flags here.\nWe don't need any\nof them. Let's kick\nit off. All right,\nlet's let our agent\nsync its mental model\nwith the working code\nbase. And so you\ncan see what's coming\nhere, right? What is\nthe self-improve prompt? It\nis in fact that\ntemplate meta prompt that\ndefines how we want\nto update this related\nfile that is the\nexpertise for this specific\nproblem. Okay, and so\nhere we go. Our\nagent is just gonna\nburn through top to\nbottom everything it needs\nto to understand what's\ngoing on. And if\nsomething is out of\nsync here, it's going\nto update it. So\nhere it's doing a\nvalidation check. We of\ncourse have closed loop\nprompts inside of this,\nthere we go, we\nhave a great breakdown\nhere of all the\nlines and the truthiness\nof them. But you\ncan see here that\nit validated, where we\nhave a validation set\nin here, the expertise\nmust be managed. So\nif I open up\nvariables here, you can\nsee I have max\nlines, and so it\nchecked the line count,\nand it compiled the\nYAML file. All right,\nexpertise is accurate and\nup to date, right?\nEverything is perfect, down\nto the line numbers,\nokay? In this file,\nthere are, you know,\nline numbers. I don't\nknow where we can\nfind one here quickly.\nThere we go, line,\nyeah, line X, Y,\nZ, right? 44 instances\nof specific line numbers\nthat connect and that\nare important for the\nkey operations, okay? Very,\nvery powerful pattern. Okay.\nI'm not being all\ntoo prescriptive here, but\nthis is where you\ncan start to really\ndial in and again,\ntemplate your engineering for\nhow you want this\nfile to be written.\nSo I'm being quite\nloose here. I want\nmy agent to guide\nthe structure, guide the\nexperience. And when there's\na change, maybe we'll\nadd like an ORM,\nright? And then our\nagent will have to\nupdate the structure or\nkey ideas inside of\nthe expertise file. But\nThat's all up to\nmy agent expert. Okay,\nit's the expert. And\nthere's something important here.\nWe do say at\nsome point here, we\nshould call out something\nlike granular, right? We\ndon't want to be\ntoo prescriptive, right? Prioritize\nactionable, high value expertise\nover verbose documentation. Okay.\nAnd we also have\nthis really great line\nhere and very important\nfor some language models\nand some agents. Keep\nin mind, after you\nthrow a search, There\nmay be nothing to\ndo. This is perfectly\nacceptable. A lot of\nagents are always trying\nto do things. Make\nsure, especially when you're\nbuilding out these kind\nof advanced prompts, right?\nSelf-improving template meta prompts.\nYou need to tell\nyour agent what is\nokay and what is\nnot okay. All right.\nSo anyway, this is\na 99. line prompt\nself improving updating the\nexpertise file based on\nreal changes in the\ncodebase. This self\nimprove prompt is telling\nus that our agents\nmental model is synced\nwith the ground truth.\nThis is the equivalent\nof you going to\nthe codebase, refreshing\nyour memory on a\nfeature before you start\nbuilding and adding on\nto it. Okay. Once\nagain, here we are.\nWe have another round\nof scaling up our\ncompute more compute equals\nmore confidence and we're\ntemplating your engineering into\nour agentic processes, right?\nInto our leverage points\nof Agentic Coding. Here\nwe have a prompt,\nwe have a template\nmeta prompt, and we're\nteaching it about our\ncodebase architecture. So\ninterestingly here, we still\njust have a partial\nexpert. Agent experts have\nthree concrete steps, right?\nYou can boil it\nall down to just\nthree steps. Act, learn,\nreuse. Act. First, our\nagents take a useful\naction. The keyword there\nis useful. Then our\nagents learn and store\nnew information, right? This\nis our expertise file\ngetting updated. Then they\nreuse that information during\nan agent expert that\nknows that code the\nbest, better than anyone,\nquickly update something. Before\nwe dive into this,\nlet's just fire off\nsome more prompts, right?\nLet's have some fun\nwith our multi-agent orchestration\ntool here. And you\ncan see here that\nwe also have our\nexpert and we have\nour WebSocket expert specifically.\nAnd I just wanna\nrun this question prompt\nhere, okay? So I'm\njust gonna click this\nhere. I'm gonna ask\nwhat WebSocket events exist\nin our system. I'm\njust gonna fire this\noff and actually let's\nscale this up. So\nI'm gonna say create\nthree agents and run\nThis is an agent\norchestration system. We can\neasily quickly scale up\nmore agents against a\nspecific problem. And this\nis a really cool\nway to co-locate on\nthe right answer. Instead\nof having one agent\nanswer something for you,\nhave three, have five,\nhave 10, right? Depending\non how important it\nis that the answer\nis correct. So there\nwe go. Our orchestrator\nagent is gonna kick\nthis off. It's designed\na specialized system prompt\nand it's going to\ndo this work on\nour behalf. Okay. We\ncovered the Agentic orchestration\nin lesson four. This\nis not about the\nAgentic orchestration system. We're\njust going to use\nthis to showcase how\npowerful Agentic Experts can\nbe. We have now\ndeployed three WebSocket Agentic\nexperts to answer one\nquestion. When they come\nback with their answer,\nwe're going to be\na lot more confident\nthat they're giving us\nthe right answer. So\nyou can see there,\nyou know, we've fired\nthe exact same prompt\nto every single agent,\nright? What WebSocket events\nexist? Same thing here,\nsame thing here. We\nhave three WebSocket experts\ngetting work done for\nus, finding the answers\nto question for us\nwith their existing expertise.\nOkay, so let's go\nahead and take a\nlook at how this\nall works. All right,\nso we have multiple\nagents working in different\nsystems. Great. If we\nclick expertise, you'll see\na very similar structure.\nIt's going to collapse\neverything. And this makes\nsense, right? Our language\nmodel that built this\nlikes to use relatively\nconsistent patterns that it's\nseen inside of its\nexisting training data that\nbuilt the language model.\nOkay, here we have\na WebSocket implementation expert\nand it's driven by\nthis three step workflow,\nright? We can now\nplan, build and improve\nanything related to WebSocket\nfunctionality in this code\nbase with a single\none shot prompt. And\nto be clear, this\nprompt does compose other\nprompts. Let's go ahead\nand collapse this to\nbe super clear about\nwhat's happening here, right?\nthree step workflow where\neach of them is\ngonna kick off a\ndifferent sub agent. We're\ngonna create our plan.\nSo a classic planning\nstep. We're then going\nto build against the\nplan. You've seen this\nbefore, right? This is\nclassic prompt chaining via\njust gonna click, click,\nclick, what WebSocket events,\nbe concise, bullet points.\nOkay, so all of\nour agents have completed.\nYou can see all\nthe consumed files from\nthat agent, this one\nand our other one.\nAnd so I love\nseeing this in action,\nright? You can see\nthe non-deterministic behavior in\nthe files that each\nagent expert consumed. So\nfive files there, four\nfiles here. And so\nwe can concretely see\nthis, our orchestrator can\nsynthesize all the results\nand very interesting here,\nlet's check this out,\nright? WebSocket 3 didn't\ncomplete the task. And\nso this is another\nkey by proposition to\nscale up your compute.\nSometimes if you throw\nfive agents at the\nproblem, only one makes\nit, one finds something\nthe other didn't, the\nother finds some things\nthe others didn't, and\nthen you compose that\ntogether, you get a\nbetter result. Okay, so\nthis is correct. You\nknow, my mental model\ncan validate this. We\nin fact do have\n21 types across, I\ndon't know if there\nare seven categories, but\nthere are some 20\nWebSocket events. So agent\nlifecycle, agent communication, orchestrator\nchat system, blah, blah,\nblah, blah, blah. Okay,\nwe had our agent\nexperts build this out,\nvalidate this work. And\nyou can see the\nUI flickering here because\nour build WebSocket agent\nis updating the store\nand soon it's gonna\nupdate the actual front\nend based on the\nplan. We've talked about\nthis in previous Agentic\nHorizon lessons, but we\nare reducing and delegating\nour context. The plan\nstep here took 80K\ntokens. Our top level\nagent here has its\ncontext completely protected. All\nit did was pass\nthe return plan into\nthe builder, and once\nthe builder finishes, it's\ngonna pass the git\ndiff work, right? So\njust the work being\ndone, you know, right\nnow we can run\nGS, we can see\nall the changes that's\nhappened, and this work\nis gonna be passed\nright into our self-improve,\nand we're actually gonna\nrun, and you can\njust see this, we're\ngonna run self-improve with\ntrue, right? So we\nare indeed going to\nlook at git diff,\nthis is that first\nparameter here, right? Argument\nhint, check git diff,\nand this is going\nto be what guides\nour agent to update\nthe changes that have\nbeen made. So this\nis gonna be really\ncool to see this\nend to end, but\nyou can see here,\nthree agent experts completed\nthe work. And if\nwe want to, we\ncould have even scaled\nthis up further and\nwe can say something\nlike this, right? Create\nthree more experts using\nthe Opus model and\nhave them same prompt\nto ultra validate. Okay.\nSo we can do\nall types of things\nonce we get these\npowerful orchestration systems and\npowerful expert systems up\nand running. All right,\nso we're still building,\nbut you can see\nhere, we have that\nskill if you want,\nbuild a customization if\nyou want, overwrite the\nsystem prompt if you\nwant. There it is,\nour agent has finished,\n20 tool uses, almost\n60K tokens, right? You\nhave to protect your\ncontext windows here and\nbuild focus agents that\ndo one thing, total\nof 15 minutes or\nsomething. And then we\nhave a great workflow\nsummary, all right? And\nof course, this is\nbuilt into the report\nformat here where our\nagent is summarizing each\nstep. All right, so\nlooks great. You can\nsee all the exact\nprecise changes made. Many\nengineers get super hyped\nwhen an agent changes\na million things. I\nget super hyped when\nagents change just the\nright things, right? I\nwanna see surgical changes\nlike this. Five lines,\n17 lines, nine lines,\nfour lines, right? And\nthen we have our\ndiscrepancies change and we\ncan just see this,\nright? We can always\nprove it with Git.\nHere's our expertise file,\ngdf. What changed? You\ncan see the exact\nupdates your agent made\nto its expertise, to\nits mental model. And\nin fact, something really\ninteresting you'll find when\nyou start deploying these\nis that their mental\nmodel becomes yours. Sometimes,\nand we'll talk about\nthe best places to\ndeploy agent experts in\na moment, but I've\nfound myself more and\nmore coming into these\nexpertise files, particularly one\nof my favorite use\ncases for the agent\nexpert is around billing\nsystems, is around systems\nthat require security, it's\naround complex niche systems,\nit's around large code\nbases with many interconnected\nsystems, spread very, very\nfar apart, right? Your\naverage agent just wouldn't\nknow to connect the\ndots like that. And\neven the best agents,\nthe best models, it\nwould take them quite\na bit of time\nto search through everything\nto draw all the\nconnections. This is why\nagent expertise and having\nmental models for your\nagents is so powerful,\nall right? We have\n650 lines here of\na map, right? A\nwrapper around the web\nsocket capability between my\nbackend and the front\nend of the multi-agent\norchestration system. This scales\nvery, very well. So\nanyway, so here's the\ngit diff, right? We\ncan see all the\nexpertise, yada, yada, yada.\nWe can see everything\nthat was updated. And\nif there's something we\ndon't like, if there's\nsomething that's wrong or\noff, we're gonna do\nsomething really important. We're\nnot going to update\nthe expertise file. And\nthis directly emphasizes the\ntrend of building the\nsystem that builds the\nsystem. You wanna update\nthe agentics that are\noperating your code, you\nwanna update the self-improve\nstep that operates your\nexpertise, okay? These are\nboth the same thing.\nWhat I'm saying here\nis this is the\nkey message of Tactical\nAgentic Coding and Agentic\nHorizon. Build the system\nthat builds the system.\nDo not work on\nthe application layer. You're\nwasting your time. Someone,\nlike a lot of\nthe engineers that take\nthis course, we are\nbuilding the agentic layer,\nthe system that builds\nthe system, right? the\nring, the new ring\naround your codebase\nthat can operate it\nfor you, with you,\nand without you, right?\nSo that's what this\nagents, just like we\nmentioned here, right? The\ndatabase is one of\nthe most important pieces\nof every application. How\nyou structure this determines\nhow everything else works,\nruns, and integrates back\ninto your database. So\ndatabase experts are fantastic.\nDevOps agent experts, right?\nWe have integration agent\nexperts, especially when you\nhave a tricky in-house\nor third-party integration or\nthree to four way\nintegrations. ML data science,\nagent experts are great.\nYou can build experts\nthat know your data\nsets, that know your\nAI tooling, that know\nyour agent sandboxes, that\nknow your available compute.\nAnd just to mention\nit, what we've built\nhere so far with\nour two agent experts,\nthese are relatively simple.\nThey have no custom\ntools, they have no\nspecialized system prompt. This\nis just the beginning\nof what's possible, all\nright? What else do\nwe have, right? We\nhave API agent experts,\nso you can keep\nyour front end and\nyour back end synced\nperfectly. And one of\nmy favorites, like just\na data types, right?\nData models, data structure,\nagent expert to keep\nall of your data\ntypes across all of\nyour one to N\ncodebase and microservices,\nkeep them all in\nsync. This is super\npowerful and it's a\ngreat starting place for\nyour first agent expert\nbecause there's really just\na handful of type\nfiles that you need\nyour expertise data structure\nand self-improve prompt to\nreference. Okay, there are\nmany, many more. That\nshould give you an\nidea of a few\nplaces you can get\nstarted, okay? Let's take\na moment here to\nstep outside engineering agent\nexperts that are all\nabout running your code\nbase and supercharging your\nagentic layer and take\na look at Product\nAgentic Experts. So, What\nwe're gonna look at\nhere is a seed\nof an idea. A\nseed of an idea\nof how you can\nuse the agent expert\npattern to enhance your\nuser experiences. We have\nNiall, this is a\nshopping application. This example\nis rough. Agents are\nnot ready to be\nshopping recommendation engines yet.\nThey're too slow, but\nwhat we have here\nin this mock app\nthat I had a\nfew agents create for\nus, what we have\nhere is the key\nideas for agent experts\ninside of your user\ninterfaces. All right, I\nhave this really blatant\npanel built into this\ndemo application, you can\ncheck out act, learn,\nreuse. This is what\nit's all about. This\nis the agent expert\npattern. Now, when we\nput this into a\nUI, this is where\nthings get really interesting,\nright? The key is\nto constantly build up\nyour agents mental model.\nIn this case, right,\nwhen we start deploying\nit against hundreds and\nthousands of real users,\nit means we're going\nto have a data\nstructure and mental model\nper user. All right,\nnow this gets very,\nvery powerful, right? This\nis personalization to the\nmax and especially when\nyou combine that with\ngenerative UI. This generation\nwas created by a\npowerful Opus model. I'm\ngonna drop this down\nto a Haiku model\njust for speed purposes.\nAnd so I have\nthis in the agent\nexpert And you can\ntell here my mental\nmodel around this is\nstill pretty fresh because\nI was able to\nhop to that very\nquickly. So, you know,\nwe'll refresh this and\nlet's just walk through\nwhat's happening here. So\nright now our agent\nis building out a\npersonalized experience for us\nin the shopping experience,\nokay? Again, control K\nto see our blatant\nexpertise file in the\nUI. It has seen\nnothing. There's no expertise\non me yet, right?\nI'm a new user.\nBut as soon as\nI take a useful\naction that changes completely,\nlet's do it. So\nI'm gonna close this\nand let's say I'm\ninterested in the, let's\njust do a search\nhere, right? Let's say\nI'm interested in, let's\nget real, we're all\nlooking for that, sure,\nyeah, Nvidia DGX, okay?\nSo these are all\nmock products, by the\nway, these don't represent\nthe real companies or\nproducts in any way,\nokay? So I'm gonna\nadd this to my\ncart and then I'm\nmeans that right. X\nmeans Y right based\non all the users\nwe've seen, right based\non X star or\nX I, this means\nY. Okay. So this\nmeans we can for\nthis right here, we're\njust using personalized user\nactions, of course, and\nreal recommendation engines. You're\ngoing to want to\nlook at the entire\ngraph of when users\nclick this, when they\nclick this category, this\nprice range, they also\nwanted that and that\nand that, right? This\nis just the seed\nof this big idea\nthat you can deploy\nAgentic Experts against, all\nright? So act, And\nthen we have another\nlearn and guess what?\nWe've reused it when\nwe regenerated this page.\nSo we can continue\nwith this, okay? Say\nwe wanna look at\nthis fan, right? Fantastic,\nright? So we have\nthis, or sorry, not\nthis fan, Blackwell GPU,\nall right? So we\nadd that, great. And\nthen we can come\nback and over and\nover our agent is\ngonna shape the user\nexperience, right? Based on\nyour interest in video\nGPUs and professional workstations,\nit's gonna give us\nnew components, new UIs,\nnew products to look\nat, all right? So\nthere we go. We\nnow need a powerful\nprocessor. Fantastic. And then\nwe've got some random\nstuff here. You always\nwant to insert some\nnew directions for your\nagents to go down,\na new graph, a\nnew pipeline. I've encoded\nthe system prompt in\nhere as well. This\nis super key. This\nis the formatted mode.\nLet's go to raw.\nAnd you can see\nthis is the actual\nsystem prompt of this\ncustom shopping agent expert.\nSo you can see\nhere dynamic variables. We\nhave the checked out\nproducts, nothing yet. products\nadded to cart, right?\nThis is embedded inside\nthe system prompt. You\ncan put this in\nthe system prompt or\nthe user prompt. We\nhave our viewed products\nhere and then we\nhave available categories and\nwe start getting into\nthe instructions and the\nactual system with the\nprompt. And we're going\nto of course just\ncrack this open, right?\nLet's go ahead and\nlook at the real\nversion, underscore system prompt.\nWe can quickly reference\nall of our agent\nsystem prompts here. And\nthen we can just\ntake a look at\nthe structure for a\nmoment. This is what's\nguiding the shopping experience.\nIt is incredible that\nyou can build something\nlike this that could\npotentially guide and steer\nhigh value user experiences,\nadaptive user experiences inside\nof a single prompt.\nOf course, there's some\nmore prompt and some\nlegitimate engineering work that\nneeds to happen to\nuse this agent, but\nit's very powerful that\nin natural language, we\ncan define so many\nrules about how we\nwant our engines of\nadaptive user experience to\nwork. For instance, we\nhave variables here. If\nwe close dynamic variables,\nyou'll see our static\nvariables, and we can\njust quickly change products\nper section and the\nsections range, right? So\nwe just have these\nvariables that dictate how\nmany items show up,\nhow many products show\nup. We have a\nnice set of instructions\nhere and so on\nand so forth. This\nis all going to\nbe available to you\nto check out. The\nkey here is what\nhave we done? We've\ntaken our agent expertise,\nwe've applied it to\na per user basis\nlevel, and then we've\ncreated a prompt that\ncan guide that individual\nuser experience by generating\ncomponents on the fly.\nThis is just one\nexample of how you\ncan set up your\nagent experts inside of\nyour products. All right,\nso I just wanna\ngive you this idea.\nSome engineers are already\non this pathway, but\nthe key here is\nthat user-specific data, right,\ndown to that action\nlevel, so that when\nthey act, your agent\nlearns, and then it\nreuses to enhance the\nexperience. Now, as we\ncontinue to add things\nand as your user\ntakes actions, right, over\nand over and over,\nsay we add a\nbunch of those, say\nwe're looking for some\nmore storage, right, we\nadd a bunch of\nthese, you know, we\nwant some monitors or\nsay we want, you\nknow, some type of\ngreat device, right? As\nyour user does more\nand more things in\nyour system and then\nchecks out this insane\nshopping spree here, something\nis gonna happen to\nyour expertise file and\nto your information about\nyour user, right? It's\nthe pattern, act, learn,\nreuse, prompt first so\nthat you can execute\nit by hand manually.\nYou can iterate quickly,\nthen scale it into\nwhatever abstraction you want.\nBut seeding is all\nabout not being too\nspecific. Ideally you run\nyour self-improve prompt and\nit creates the expertise\nfrom blank. And then\nyou can update your\nself-improve tweak it and\nrerun it, right? You\ncan rerun yourself improve\nas many times as\nyou need to. And\nyou really want to\nrun it until your\nagent stops finding new\nthings, right? When it's\nmental model does lock\nin with a sufficiently\nsmart enough model, it\nwill stop looking for\nimprovements. So what's another\nproblem and trade off\nwith agent experts. Some\nengineers will say, now\nI have to maintain\nanother source of truth.\nOnce again, This is\nnot a source of\ntruth. This is a\nmental model, okay? And\nyour agent should take\ncare of this for\nyou if you write\na good enough self-improve\nprompt, okay? This is\na trend among all\nAgentic Coding, among all\nagentic engineering. You will\nhave to invest in\nteaching your agents how\nto do things. That\nis the next massive\ngap between engineers who\ntaught their agents how\nto run things and\nwho didn't, who's still\nprompting in the loop\nby hand that same\nprompt they wrote months\nago over and over\nand over, okay? This\nis where winners are\ngonna start emerging. They\ntype one prompt, right?\nI typed one prompt,\nand a feature was\nbuilt out. We'll have\nto invest in getting\nit right. What's another\nproblem with Agentic Experts?\nFinite context problem. You\ndo not want this\nfile to infinitely grow.\nIt just cannot. But\nthis shouldn't be that\nhard to manage. Your\nmental model of all\nthe codebases you've\never operated in, it\ndoesn't infinitely grow, right?\nIt grows at some\nsteady pace as you\nunderstand things. And then\nonce you get to\na certain level, you\njust forget. That is\nokay. The question is,\ncan you, based on\nyour mental model, get\nback in to all\nthe critical parts of\nthat system. I have\nhad no problem staying\nunder 1000 lines in\nthe systems I operate\nin with my expertise\nfiles. And you know,\nwe are operating here\nin YAML, there are\nmany more compressed ways\nto express your data\nstructures, play with them,\nexperiment with them, pick\nyour favorite. I'm sure\nnew ones will or\nhave emerged to best\nexpress information to agents\nconcisely, keeping that token\ncost low. But I\nreally like YAML so\nfar. Of course, the\ndatabase is gonna be\nthat primary location, right?\nJSONB blobs for your\nexpertise. Finite context is\na thing. That's why\nI have the max\nline limitation. And that's\nwhy it's reinforced in\nthe prompt. The agent\nmust enforce this on\nan agent expert. When\ndo you want to\nbuild an agent expert?\nLet's go ahead and\ncollapse everything and focus\nin here. They're great\nfor user specific use\ncases. In fact, I'm\nbetting great user facing\nproducts of the future\nare going to be\nagent driven. They're going\nto be agent experts,\nright? And the absolute\nbest case, a single\nagent will have an\nentire database of information\nabout a user that\nit can execute on,\nright? Depending on where\nyou are in the\nfuture, you might be\nseeing this already in\nmany agent first applications.\nThe trick here is\nto keep latency down\nwhile your agent figures\nthings out. We're gonna\nneed to deploy a\nlot of UI hacks.\nWe're gonna need to\ncommunicate active loading bars,\nthings in the meantime\nto keep the user\nengaged while the agent\nreally builds the best\npossible experience in the\nbackground via tool calls\nand whatever comes next.\nI highly recommend building\nout code-based agent experts\nfor managing very high\nrisk or and high\ncomplexity areas of your\ncodebase. For instance,\nI don't build any\nbilling system or any\nsecurity-focused layer without building\nan expert. So I\ncan always just ask\nmy expert questions. I\ncan query my experts\nabout specific areas so\nthey can manage it\nbetter than I ever\ncould. And that expertise\nfile, it doesn't get\nfuzzy like our expertise\ndoes. Their expertise file\nis just there. It's\nalways there. I have\ncaught revenue changing details.\nAnd let me be\nsuper clear here. My\nAgentic Experts have caught\nrevenue changing details in\nthese systems and security\nspecific details because they\nwere experts. They had\nall the details of\nall the nitty gritty\nthings. And if you,\nand I'll bet you\nhave, if you've been\nan expert in a\nspecific area of your\ncodebase, you know\nthat there are some\ntricky tricks there are\nsome tricky tricks that\ncan get even the\nbest engineers, okay? We're\ntalking down to runtime\nexecution of nasty SQL\nORMs. We're talking about\nML models that if\nyou don't tune that\none variable, right, that\none setting, it messes\neverything up. There are\nmany examples like this\nthroughout engineering. So many\nfoot guns, so many\nissues, especially as your\nproduct grows. And this\nis a key idea\nI wanna communicate to\nyou. If your product\nis successful, it will\ngrow and complexity and\nspeciality. As that happens,\nagent experts become more\nand more valuable to\nhelp you manage that\ncomplexity. When you set\nup the right act,\nlearn, reuse structure for\nyour agent experts, and\nwhen you dial in\nor let your agent\nmanage that data structure,\nright? The shape of\nthat mental model, okay?\nSo as the complexity,\nas the size of\nyour codebase grows,\nthe agent expert becomes\nmore valuable. So I\nalso recommend you build\nan agent expert when\nyou see high error\nrates around specific areas\nof your codebase\nwhere you keep trying\nto deploy an agent\nand they keep getting\nit wrong. This is\nwhere you can deploy\na specific agent expert,\nright? You can come\ninto your self-improve prompt\nand modify a couple\nkey ideas that say,\nhey, pay strong attention\nto this idea. Make\nsure this is part\nof your mental model,\nokay? It's okay to\nbe prescriptive, right? Some\nof engineering is very\nprescriptive. We don't want\nanything fancy happening here,\nokay? So when should\nyou not use an\nagent expert? Avoid this.\nif your problem doesn't\nevolve or change over\ntime. There's a part\nof your codebases,\na part of your\nproducts, it just hasn't\nchanged, right? So who\ncares, right? Why do\nyou need a dynamic\nevolving agent for that?\nYou don't. Deploy an\nout of the box\ngeneric agent that's just\nthat classic good engineering\nagent and just have\na dedicated isolated file\nand you want to\nexplicitly say, hey expert,\nI need you, help\nme do this. Agent\nskills are great for\nthis. You can build\nout your agent experts\nas a skill, as\nI mentioned. This does\nnot matter, okay? Skills\nboil down to prompts,\nokay? If you like\nthe ergonomics of that,\nif you like the\nergonomics of a sub-agent\nso you can parallelize\nit, use whatever abstraction\nyou want. Just remember,\nI always like to\nstay close to that\nbare metal, so I\nrecommend the same for\nyou. Everything becomes the\ncore four. Context, model,\nprompt, tools. Every abstraction\non top of that\nIt's just that. It's\nan abstraction. It boils\ndown to the same\nthing. I focus a\nlot more on principles\nof AI coding and\ntend to avoid these\nabstractions for, especially like\nfor these new patterns,\nright? What is it\nreally, right? What is\nan agent expert really?\nYou don't want it\nto be intermingled with\nexisting other abstractions. confusing\nthen. But again, build\nwhatever works for you\nand your team. I'm\nnot trying to sell\nyou on any particular\nidea. Take the pieces\nhere that you like,\ntake the pieces here\nthat work and build\nexperts in your own\nway. Okay. So when\nwe zoom out and\nwhen we look around,\nexperts are the true\nvalue generators of the\nworld. They're the 80,\n20 of the world,\nright? Of engineering, of\nbusiness, of whatever you're\nin. True expertise is\nwhat people pay for.\nExpertise drives true innovation\nand change. For example,\nright, like in the\ntech ecosystem, data scientists,\nML engineers, AI engineers,\nAgentic Engineers, engineers that\nbuild the system, that\nbuild the system, are\nthe cream of crop\nfor engineering. Why is\nthat? It's because there\nis expertise required here.\nWe are in a\nloop of ever-growing act,\nlearn, reuse loops that\nbuilds our expertise. So\ninside of your code\nbases, whenever you have\nniche information or you\nwant to build a\nspecialized operator for a\nspecific problem in your\ncodebase, consider building\nan Agentic Expert inside\nof your products. I\nhighly recommend you start\nexperimenting with product focused\nAgentic Experts that let\nyou build adaptive UI\nUX for your users.\nI think there's a\nwhole new class of\nproducts waiting to be\nbuilt on top of\nthis pattern on top\nof agent experts. You\nknow, here's a simple\nquestion for you as\nwe part ways today.\nDo you want a\ngeneralist working on your\ncodebase that forgets\nevery time they work?\nOr do you want\nan expert that remembers\nand learns from the\nwork done so that\nthe next time they\nshow up, they start\nwith a powerful working\nunderstanding of the system?\nGreat work here. In\nthe final lesson of\nAgentic Horizon, we'll focus\non one of the\nmost important topics of\nagentic engineering, codebase\narchitecture in a world\nwhere agents are the\nbest tool for engineering.\nWe'll cover optimal shapes\nfor your codebase,\nso you can scale\nthe performance of your\nagentic layer. We'll tie\nit all back to\nthe one big idea\nof Tactical Agentic Coding\nand Agentic Horizon. You\nand I, the Agentic\nengineer, we build the\nsystem that builds the\nsystem. We prioritize agentics.\nI'll see you in\nthe final lesson of\nAgentic Horizon.",
  "summary": "This lesson addresses the massive problem with agents: they forget, which means they dont learn. Traditional software improves as its used, but agents dont. Memory files are global forced context that must be manually updated. Agent Experts solve this with a three-step workflow: Act (perform the task), Learn (extract and store expertise), Reuse (load relevant expertise for future tasks). The lesson covers meta-agentics: meta prompts, meta sub-agents, and meta skills. Expertise is stored in YAML files or JSONB database blobs with enforced max line limitations to keep token costs low. Agent Experts are great for user-facing interactions, domain-specific operations, and any area where accumulated knowledge improves performance over time.",
  "key_concepts": "1. THE MASSIVE PROBLEM: Agents forget, which means agents dont learn. Traditional software improves with use, but agents start fresh every time.\n\n2. ACT, LEARN, REUSE: The three-step workflow for Agent Experts. Act (perform the task), Learn (extract and store expertise), Reuse (load relevant expertise for future tasks).\n\n3. MEMORY FILES LIMITATIONS: Global forced context that always loads, must be manually updated, consuming your time. Expertise requires breaking rules when the time is right.\n\n4. AGENT EXPERTS: Agents that actually learn and grow. They update their knowledge about their domain. Experts never stop learning - the game ends only when they stop.\n\n5. META-AGENTICS: Meta prompts, meta sub-agents, and meta skills. The atoms that make up the Agent Expert - agents that operate on and improve other agents.\n\n6. EXPERTISE STORAGE: Store expertise in YAML files or JSONB database blobs. Keep under 1000 lines with enforced max line limitations to control token costs.\n\n7. FINITE CONTEXT AWARENESS: The agent must enforce context limitations on itself. Compressed data structures (YAML) help express information concisely.\n\n8. ORCHESTRATOR INTEGRATION: Use the orchestrator agent to manage Agent Experts that operate specific areas of your codebase.\n\n9. USE CASES: Agent Experts are great for user-facing interactions, domain-specific operations, and any area where accumulated knowledge improves performance.\n\n10. MENTAL MODEL BUILDING: Even if you forget details, can you get back to all critical parts of a system based on your mental model? Expertise files help preserve this."
}