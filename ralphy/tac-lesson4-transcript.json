{
  "video_id": "afk-agents",
  "url": "https://agenticengineer.com/tactical-agentic-coding/course/afk-agents",
  "title": "AFK Agents: Let Your Product Build Itself",
  "channel": "Agentic Engineer",
  "duration": 2787,
  "language": "en",
  "language_name": "English",
  "is_auto_generated": false,
  "extracted_at": "2026-01-14T02:56:02.586Z",
  "transcript": "Welcome to lesson four\nof Tactical Agentic Coding.\nIn this lesson, you\nstep out of the\nloop and you let\nyour product build itself.\nHow is this possible?\nWe do this by\nadding four elements of\nAFK agents. This enables\nyou to trigger your\nagents to run in\ntheir own environment. By\nthe end of this\nlesson, you'll know exactly\nhow to replace and\noutperform modern cloud-based agentic\ncoding tools like Copilot,\nDevon, Jules, Codex, and\nother in-the-cloud coding agents.\nThese tools are great.\nI've used them all,\nbut they lack the\ndetail needed to ship\nend-to-end in your code\nbase with your engineering\npractices for your domain-specific\nproblem. They all have\nnatural limits because they're\nliterally designed for everyone's\ncodebases, not yours.\nJust like the prompt,\nYour agentic pipeline is\ntoo valuable to outsource\nto a third party\ntool, especially this early\nin phase two of\nthe generative AI age.\nYou want to own\nyour agentic pipelines. You\nwant to be able\nto slice and dice\nyour agents across your\ncodebases, across the\nsoftware developer lifecycle with\nease. In this lesson,\nwe put together the\nplan and build step\nof the software developer\nlifecycle to augment and\nautomate your codebases.\nEvery tactic you'll learn\nwas created to be\nsimple, compressed mental frameworks\nyou can use every\nsingle day for your\nengineering work. First, you\nstop coding. Our hands\nand mind are no\nlonger the best tool\nfor the job of\nwriting code. Then you\nadopt your agent's perspective\nso you can maximize\nthe leverage you get\nfrom your agents then\nyou template your engineering\nso you can deliver\nconsistent results in complex\ncodebases across hundreds\nof agent executions and\nnow here in lesson\nfour you stay out\nthe loop what does\nit mean to stay\nout the loop there\nare two types of\nagentic coding both powerful\nboth relevant but one\nlets you hand off\nexponentially more work to\nyour agents. You've of\ncourse heard of human\nin the loop. When\nit comes to agentic\ncoding, this is what\nmost engineers are doing\nright now. The tech\necosystem has become obsessed\nwith human in the\nloop systems and most\nfail to recognize the\ntrend that there are\nincreasingly more chores, bugs,\nand features that don't\nrequire your expertise at\nall. If you encode\nthem, they're sitting on\ntheir device in the\nloop, prompting back and\nforth and back and\nforth, burning their precious\ntime on work that\ncould be handed off\nto the right team\nof agents in the\nright order with the\nright templates. This is\nclassical in-loop agentic coding.\nAnd then there's of\ncourse Outloop. Outloop agentic\ncoding is off-device agentic\ncoding. It's when you\nwrite high to low-level\nprompts that you pass\noff to your agentic\npipeline, then you go\nAFK, away from keyboard.\nYou walk away from\nyour keyboard, or maybe\nyou were never there\nin the first place.\nMaybe you sent the\nprompt right from your\nphone on GitHub, Slack,\nNotion, Jira, a text\nmessage, or any third-party\ntool. Stay out the\nloop, is a tactic\nof agentic coding that\nreinforces the fact that\nmodels will improve and\ntools will change. This\nmeans over time, your\nagents will be able\nto solve more and\nmore problems with every\nimprovement. When you stay\nout the loop, you\nleverage this fact, enabling\nyou to focus on\nscaling up what your\nagents can do instead\nof wasting time doing\nthe work yourself. You\nbuild the system that\nbuilds the system. This\nis where we need\nto focus. Why is\nthat? It's because this\ndirectly ties into our\nability to improve our\nagentic coding KPIs. We\nwant presence down, size\nup, streak up, and\nattempts down. What's the\nbest way to accomplish\ngreat agentic coding KPIs?\nYou guessed it, stay\nout the loop and\nfocus on building the\nsystem that builds the\nsystem. We're going to\naccomplish this by adding\na net new agentic\nlayer to your code\nbases. This is gonna\nbe different It's gonna\nbe a little challenging\nand it's going to\nbe incredible if you\ntake action on this.\nHere in TAC, Tactical\nAgent of Coding, we're\nobviously capitalizing on this\nopportunity before it hits\nthe masses. We're not\nplaying today's game, we're\nplaying tomorrow's. You might\nbe thinking about how\nerror-prone LLMs and agents\ncan be or how\nAI can't possibly ship\nyour special snowflake work\nend to end. Let\nme say this bluntly\nand clearly. If you\nare not wrong now,\nyou will be. It's\nonly a matter of\ntime. Remember, tools will\nchange and models will\nimprove. That means engineers,\nteams, leaders, and businesses\nbetting on the future\nare the ones that\nwill get ahead today.\nThere's no way around\nthis. Keep it simple\nand bet on the\nfuture. Lean into this.\nYou want to be\nthe one shipping more\nfeatures with less friction,\nwith fewer errors agentically,\nhands off, AFK. This\nmeans you get to\nproduct market fit faster\nand you expand your\ntotal addressable market faster\nwith every day, with\nevery improvement you make\nto your templates and\nto your agents. Your\ncurrent velocity is fractions\nof what it will\nbe when your agents\nare doing all the\nheavy lifting for you\nbecause you've learned to\nstay out the loop\nand build the system\nthat builds the system.\nStaying out the loop\nsounds great. how does\nit actually work and\nhow can we differentiate\nfrom the plug and\nplay outloop agentic coding\ntools that already exist\nwith everything you've learned\nso far here in\ntech we can automate\nnearly half the software\ndevelopment life cycle and\ngo from prompt to\npr in lesson three\nyou learn to template\nyour engineering investing in\nyour templates is mission\ncritical for outloop agentic\ncoding because when you\ntemplate your engineering you\nencode your engineering solutions\ninto your codebases\nfor your agents. Notice\nhow it keeps stressing\nthe uniqueness and the\nownership of your code\nbase and your agents\nas much as the\nbig gen AI companies\nbuilding these Outloop apps\nand tools want you\nto believe this one\nsize does not fit\nall, especially as your\nproduct grows and becomes\nunique and differentiated. In\nthis lesson, we chain\nyour templates together inside\nthe highest leverage point\nand the highest composition\nlevel of agentic coding,\nthe ADW, AI. developer\nworkflow. An ADW is\na reusable agentic workflow\nthat combines code, agentic\nprompts, and agents to\ndeliver results autonomously. On\nthe battleground of agentic\nengineering, the ADW is\nhow you create this\nnew agentic layer around\nyour codebase. It's\nthe synthesis of previous\ngeneration deterministic code and\nnew generation non-deterministic language\nmodels, prompt chains, and\nnow agents. The ADW\ncan be thought of\nas an agentic pipeline\nor very loosely speaking\nan agentic workflow. In\nthe future these will\njust be known as\nscripts and will fully\nexpect agentic behavior by\ndefault. We're creating a\nconcrete term for this\npulling it from principle\nto decoding to be\nabsolutely clear about how\npowerful and differentiated this\nunit of engineering is.\nAI developer workflows are\nwhat we'll use to\nautomate not just the\nsoftware developer lifecycle, but\nall engineering work and\nall workflows you want\nyour agent to operate\non your behalf. If\nyou understand this lesson\nand start putting these\nideas to work in\nyour codebase, you'll\nfast track your transition\ninto the future of\nAgentic coding, while other\nengineers are sitting at\ntheir device, prompting back\nand forth and back\nand forth, wasting time\non problems their agents\ncould solve. While they're\ndoing this, you'll have\nbuilt a new agentic\nlayer around your code\nbase where you stay\nout the loop and\nlet your product build\nitself. In order to\nbuild Outloop systems, we\nneed AFK agents, agents\nthat run while we're\naway from the keyboard.\nThere are four elements\nof AFK agents we\nneed to build our\nOutloop system. This is\nwhat we're going to\nfocus on here in\nlesson four. The four\nelements are prompt input,\nthe trigger, you'll need\nan environment, and then\na review system. These\nfour elements can be\nremembered with Peter. These\nmake up the four\nelements of AFK agents.\nPeter, prompt input, trigger,\nenvironment, review. With this\nsetup, your agents can\nrun while you're AFK.\nAFK agents are the\nagents you'll build to\nrun the loop while\nyou stay out of\nit. In this lesson,\nwe'll run two ADWs\nhave this configured here.\nAll the information you\nneed to set up\nyour own workflow using\nthe elements I'm going\nto run here are\ngoing to be linked\nin your loot box.\nBut I recommend you\njust watch to start\nand follow along at\na high level. Don't\nget bogged down in\nthe configuration of this.\nJust watch this through\nfirst. and then start\nsetting up your four\nelements. That's the trigger.\nI have a GitHub\nweb hook set up.\nAnd then for the\nenvironment, I'm going to\nuse this Mac mini\nhere that my agent\nhas full control over.\nIf we open up\nscreen sharing, you can\nsee I have an\nagent ready and waiting,\nlooking for requests from\nthe web hook right\nhere and we'll dive\ninto exactly how this\nworks in just a\nmoment but this is\nour environment we're looking\ninto this device right\nhere and when we\nkick off our prompt\ninput you're going to\nsee this start up\nand boot up in\njust a moment here\nand then of course\nour review system is\ngoing to be github\npull requests so after\nour agent finishes the\nwork we've asked for\nwith the prompt input\nit's going to turn\naround do the work\nin its environment and\nthen submit a pull\nrequest back for us\nto review. Instead of\ndiving right into the\nTAC4 codebase, let's\njust look at how\nthis simple Outloop system\nworks end to end.\nLet's of course start\nwith our prompt source,\nGitHub issues. For the\nTAC4 codebase, I'm\ngonna go ahead and\njust create a lightweight\nissue for us to\nunderstand this process. I'll\nsay ADW documentation. I'm\ngonna type slash chore\nto document the ADW\ndirectory, read everything. in\nADW then update read\nme with information how\nit works. Okay. Chores\nare the simplest unit\nof engineering work that\nyour agent should be\ntaking off your plate\nwith no debate at\nall. So let's kick\noff this ADW and\nlet's watch what happens\ninside of the agent\nenvironment inside of this\ndevice here that we\ncan see. So I'm\ngoing to kick this\noff. We're going to\ncreate a brand new\nissue here and check\nthis out right away.\nYour agent is getting\nto work for us.\nSo If we click\nhere, we can see\nwe're getting GitHub issue\ncomments. We're getting a\nlive feed of the\nprogress of our agent.\nYou can see it's\nclassified the issue as\na chore. In our\nprevious lesson, we looked\nat chores, bugs, and\nfeatures. This is how\nwe can specialize certain\nagents and certain prompts\nto solve different problems\nin your codebase,\nright? So we have\na brand new branch\nand it's starting to\nwork on the implementation\nplan. You can see\nthe software developer lifecycle\nplanner has taken over\nand it's going to\nstart shipping. This is\nall running on this\ndevice here. As you\ncan see here, it's\nposting comments and it's\nworking through the current\nimplementation plan right now.\nSo this device, this\nagent is doing this\nwork autonomously for us.\nNot only that, we're\ngetting a nice live\nfeed of what's actually\nhappening. By separating our\nagents, we're able to\nisolate the big three\ncontext model in prompt\nto solve one problem\nand solve one problem\nwell. Just in these\nfour steps, we have\nseveral micro agents doing\ntheir work, solving a\nspecific problem well, right?\nSo we had a\nprompt to classify this\nwork for spending up\na new branch. And\nthen of course we\nhave an implementation plan.\nAnd so our planner,\nyou can see our\nplanner is completely done.\nIt's committed its work\nright here. We can\nsee that it's created\na brand new spec\nfile agentically. And now\nour implementer agent is\ngoing to start implementing\nthe solution. So its\ncontext window is completely\nfree. We can select\na more powerful model,\nwhich I recommend you\ndo for the implementation.\nAnd we can, of\ncourse, use the plan\nthat was created by\nour planner as the\nprompt for our implementer.\nSo you can see\nhow all these elements,\nevery piece of our\nADW, our AI developer\nworkflow, it all depends\non the fundamental principles\nof AI coding and\nof agentic coding. These\nideas, these concepts, they\ndon't go anywhere. They\ngo everywhere, right? These\nare ideas that will\nalways exist and we\nneed to Pay attention\nto them with each\nprompt, with each agent.\nThe details are everything.\nThere's a reason why\na lot of agent\nencoding tools don't work.\nIt's because they don't\nunderstand your codebase.\nThey don't understand how\nyou work. And by\nencoding them into our\ntemplates and then chaining\nour templates, our meta\nprompts and our reusable\nprompts together, we get\nan ADW that can\ndo work like this,\nokay? You can see\nthe solution was implemented\nand now we're committing\nthe implementation. Our agent\nworking on its own\ndevice here is running\nthrough this ADW, this\nAI developer workflow. It's\ncreating a PR. All\nthis work is happening\nwithout us. Okay. But\nit's happening as if\nwe were building it\nbecause we've templated our\nengineering. Okay. Success is\nof our chore, just\nlike in the tack\nthree lesson, our chore\nis getting expanded into\na full plan. And\nthen our implementer is\nbuilding it out. All\nright, so now we\ncan check out what\nwas done. All right,\nso if we click\nthis PR, you can\nsee top to bottom,\na just a great\nclean write up of\nthe work completed, right?\nSo this PR address\nis 31. You can\nsee the plan there.\nAnd then you can\nsee the changes that\nwere made. Okay, so\nif we scroll down,\nyou can see everything\nlooking good. And you\nknow, there are issues\nhere that I need\nto clean up that\nI need to encode,\nright, we have a\ngentic developer workflow, that's\njust wrong. So this\nis something that I\nneed to improve in\nmy prompt to be\nclearer about what this\nis. But you can\nsee here, if we\ngo to files change,\nwe can see just\nthose files we asked\nfor to be updated.\nThere's the readme. We\ncan quickly just scroll\nthrough this. I don't\nwanna get too hung\nup on the details\nhere, but you can\nsee we have changes\nfor the readme detailing\nexactly how everything works.\nFor the ADWs, there's\nthe webhook that's running\nthis workflow, cron, and\nthen the build step.\nand then the actual\nADW, which we're gonna\ndive into in just\na moment, environment variables,\nprerequisites, so on and\nso forth, right? So\nthere are no limits\nhere, right? Your ADWs\ncan operate on your\nADWs. So, you know,\ndon't get too meta,\nlet's keep it simple.\nYou can see more\ndetails there. And then\nof course we have\nthe plan, right? This\nplan was built by\nour planner agent and\nthen handed off to\nour implementer agent. So\nthis was the, literally\nthe prompt for our\nimplementer agent. So you\ncan see top to\nbottom there exactly what\nthat looks like. So\nthis is awesome. This\nall happened with Peter,\nthe four elements of\nAFK agents. For the\nprompt input, we use\nGitHub issues. For the\ntrigger, we set up\na GitHub web hook.\nYou can see that\nright here. I'm gonna\nblur out my URL\nhere. You can set\nup your own web\nhook right here. And\nthen our device operating\nright here picked up\non that and ran\nour ADW, our plan,\nbuild a developer workflow\nand then it submitted\na PR back to\nour review system and\nwe reviewed the PR.\nSo here we just\nhave two steps of\nthe software developer lifecycle\nfully automated end to\nend. I hope you\ncan see how powerful\nthis can be, right?\njust halfway through TAC,\nwe can automate the\nkey steps of the\nsoftware developer lifecycle. Obviously,\nwe're gonna take this\na lot further. We're\ngonna push this, but\nright now, let's dive\ninto the details of\nhow this works so\nthat we can see\nthe ADW, AI developer\nworkflows are in fact\na composition of key\nprimitives that we can\nwork with to build\nan agentic layer around\nany codebase you\noperate in. So keep\nin mind as we\nwork through this that\nthese four elements They\ncan be anything, right?\nI'm not here to\ntell you what tool\nor what environments to\nuse, right? What sandboxes\nto put your agents\nin. I'm here to\ngive you a top-notch\nframework and tactics you\nneed so that you\ncan build a system\nthat works for your\ncodebases, your products,\nand your team. You\nwill, and you should\nhave opinions about how\nto structure your AFK\nagents. Don't read into\nhow this is configured\ntoo much. Focus on\nthe composable units. All\nright, so let's dive\ninto this. Let's run\nthis again, only this\ntime, Let me go\nahead and kill the\nweb hook so we\ndon't get this kicked\noff. So I'm going\nto disable this agent\nhere because this time\nwe're going to update\nso that our environment\nis my local device\nand my trigger will\nbe a local script\nwill run right out\nof the TAC 4\ncodebase. So let's\ngo ahead and open\nup the terminal. And\nthis is a great\nplace to follow along\nif you're interested. If\nwe type ls, you\ncan see we have\nreport feature. It's gonna\nset up some things,\nright? It's gonna run\nall these previous commands.\nAnd then our agent\nis going to report\nsome results to us,\nto the engineer. to\nyour coworkers executing this\nscript, right? So it's\ngonna have some useful\ninformation, you know, work\ncompleted and then action\nrequired. Okay, so it's\ntelling me, you know,\nI need to fill\nout the root level\nM and app level\nwas already copied from\ntack two and the\nAPI keys are all\ngood there. So we\ndon't need to make\nany changes there. But\nthen to set up\nour AFK agent, we\nhave this detail here\nwe need to set\nup a remote repo\nso that we can\nof course, you know,\nget access to issues\nand PRs to satisfy\nthe prompt input and\nthe review system elements\nof AFK agent. So\nI'm gonna go ahead\nand do this right\nnow. If you're following\nalong, you're gonna wanna\ndo the same, create\na new GitHub repo\nand you know, set\nup and run these\ncommands. So I am\noperating on the type\nfour codebase. So\nI'm going to reuse\nthe same URL. So\nI'm gonna run this\nhere. This of course\nwon't work for you.\nOkay, so this looks\ngreat. Let's have our\nagent kick off a\nworkflow for us. So\nhow does this new\nagentic layer of our\ncodebase work? It\nall happens here, as\nyou could guess, in\nthe ADW's directory. Let's\nfinish configuring and getting\neverything set up, and\nthen we'll run this.\nSo in the dot\nenvironment variable file, the\nkey thing you need\nhere is these two.\nSo you're going to\nneed to set up\nyour Anthropic API key.\nThe agent SDK currently\nonly runs with the\nAPI key. This may\nchange in the future.\nKeep your eye out\nfor that. I'll make\nsure there's links in\nyour loop box mentioning\nif that's changed at\nall. But so I'm\ngoing to set this\nand for your cloud\ncode path, depending on\nyour configuration, this might\nnot work right away.\nSo you need to\nrun something like this,\nwhich cloud copy this\nand just paste this\nin your environment variable\nright here. I'm going\nto set these up.\nI'm going to cut\nthis part of the\nvideo, obviously. So the\nenvironment variables are set\nup for the top\nlevel. That's great. Now,\nbefore we dive into\nthis, let's go ahead\nand create a prompt\ninput for this workflow\nto run on this\ndevice. So we'll go\nahead, open up GitHub\nissues. We'll hit new\nissue here and let's\nhave our agent build\nout a new feature\nfor us. So I'm\ngoing to type just\non L support. And\nlet me quickly refresh\nour memory here on\nthis codebase. We\ncan execute it with\nsh script start. All\nright, so this is\ngoing to kick off\nour backend and our\nfront end. There it\nis. So let's go\nahead and open this\nup. And as you\ncan see, we have\nour classic natural language\ninterface. We can upload\ntest data, we can\nget users. We can\nthen query these users,\nusers age descending. And\nthen that query will\ncome through here as\nan SQL statement against\nour local SQLite database.\nIt all looks good,\nright? So what we\nwanna do here this\nnew feature we're going\nto add json l\nsupport if we upload\nyou can see right\nnow we can only\ndo dot csv or\ndot json so let's\nkick off this adw\nwe're going to dive\ninto here in just\na moment to operate\non this for us\nand so let's go\nahead and kick this\noff the first thing\nwe need to do\nof course is write\nthe prompt input right\nthis is step one\nof the four elements\nof outloop systems of\nafk agents so i'm\njust going to write\nup a prompt here\nthis is what our\nprompt is gonna end\nup looking like here.\nWe're just adding details.\nThis is a high\nto mid-level prompt where\nruns properly. We posted\na health check onto\nthe comment. There it\nis. And we are\ngood to go. We're\ngood to run our\nAI developer workflow. So\nlet's kick this off\nand then let's break\nit down. So if\nwe open up the\ntop of our ADW\nplan build, we only\nhave one, ADW in\nthis codebase, just\nthe plan and the\nbuild. Remember we're automating\nthe plan and build\nstep of the software\ndeveloper lifecycle. And then\nwe can see the\nexact same thing, right?\nSo super simple to\nkick off. We have\nUV run this, okay?\nThese scripts, right? These\nsingle file scripts can\nbe anything you want\nusing astral UV to\nrun Python single file\nscripts. You can see\nyou have a couple\nof dependencies there. These\ncan be bund scripts\nif you want, shell\nscripts, whatever you want.\nThe whole point is\nthat they're a layer\non top of your\ncodebase. So let's\ngo ahead, copy this\ncommand, paste. Let's get\nrid of the ADW\nID. We don't need\nthat. And let's just\nrun 33. We need\nto make sure we're\ngoing into the ADW's\ndirectory here, ADW slash,\nkick it off. And\nhere we go. So\njust like in our\nenvironment, it's running that\nexact same workflow now,\nright? The only difference\nis I kick this\noff with a manual\ntrigger. It has its\nown unique ADW ID\nto identify this AI\ndeveloper workflow. And now\nit's got its own\nbranch, JSON-L support. Now\nit's gonna do this\nwork for us agentically.\nYou can see the\nbranch that we're operating\non in this code\nbase just got updated.\nOur agent has taken\nthe wheel. We are\nnow out of the\nloop, right? We said\nwhat we want done\nand now it's starting\nto do the work\nfor us. We're focusing\non the what, not\nthe how. The details\nof how things are\ndone, we've already encoded\ninto our codebase\nvia our reasonable prompts,\nour templates and our\nmeta prompts, right? That's\nall here. We'll walk\nthrough these in just\na moment here. So\nif we hop back\nto the issue, you\ncan see our agent\nis updating this live,\njust like our previous.\nThe issue has been\nclassified as a feature.\nSo instead of running\nthe chore, it's going\nto run the feature\nhere. This feature template\nmeta prompt is going\nto build out a\nentirely different set of\ninstructions and a different\ntemplate for our agent\nto fill out and\noperate on. We can\ntarget specific classes of\nproblems with this switch,\nright? With this feature\ninside of our ADW\nthat classifies is this\na chore bug feature\nor any other specific\nclass of problems that\nyou solve in your\ncodebase. All right.\nThis is a very\nimportant pattern of agent\nto code and you\nneed to be able\nto target specific classes\nof problems. So while\nour agents building this\nout on our device,\nlet's go ahead and\nbreak down how exactly\nthis works inside of\nthe codebase, right?\nHow is your agent\ndoing this work for\nus agentically? It all\nstarts in the ADW\nplan build. Here's the\nworkflow, right? It's right\nhere at the top\nof the file. Very\neasy to understand. Fetch\nthe GitHub issue details,\nright? So pull in\nthe prompt source, creating\na feature branch for\nthis work. This could\nbe a chore or\na bug as well.\nWe're then running our\nplan agent. There's gonna\nbe a clog code\nwith a specific plan\nprompt. It's gonna run\nour slash feature reusable\nprompt. Then we're gonna\nhave our build agent\ntake the plan and\nbased on the plan,\nit'll pull in all\nthe right context. Again,\nwe did this in\nour previous lesson with\nthe slash implement command.\nYou can see that\nright here. We're going\nto pass the plan\nin as an argument\nand then it executes.\nAll right. And then\nfinally, of course we\ncreate a PR. So\nright here, we're automating\nthe first two steps\nof the software developer\nlife cycle plan and\nbuild plan and code\nwith this ADW right?\nA developer workflow plan,\nbuild. Let's break this\ndown. You can see\nhere at the top,\nwe have different agents\nfor different specific tasks.\nLet's go ahead, collapse\neverything and just run\ncomment on the GitHub\nissue. or we are\nchecking the error, okay?\nAnd so in between\nall of our logging\nand reporting, we're just\nrunning the individual steps\nof our ADW, okay?\nSo here's that classify\nissue. We can go\nahead and look at\nthat, right? Classify issue,\ncheck this out. This\nis our prompt that\nwe're running as a\nslash command. And we're\njust going step-by-step. We're\nisolating all of our\nprompts so that we\ncan improve them. No\nad hoc prompts as\nstrings inside of the\ncodebase. Everything's isolated\nso that we can\nimprove it. We have\na nice mapping here.\nOf course, if you\nhave more detailed or\ndifferent classes of problems,\nyou just add them\nhere in your classify\nissue step. And then\nyou update your data\ntypes to support the\ndifferent types of slash\ncommands that you solve.\nAll right. And again,\nthis is just one\nway to build out\nan ADW. We're just\nwalking through this so\nyou can understand how\nyou can build these\nout for your code\nbase, for your problem,\nfor your application, for\nyour team, for your\nusers. Right. So there's\nthat. We then We\ncreate a Git branch\nand again, it's the\nsame process, right? Git\nbranch is created by\nour branch PR. Notice\nhow with every one\nof these templates, we're\nencoding our engineering into\nreusable prompts that our\nagent can tap into,\nokay? And this is\nall about that same\nidea, that same tactic.\nWe need to adopt\nour agent's perspective behind\nthat We need to\ngive our agent our\nperspective, right? They need\nto see what we\nwould see when we're\nsolving that specific step\nof the AI developer\nworkflow, right? Because previously,\nthese are just developer\nworkflows. This is what\nyou and I are\ndoing on the ground\nevery day. But now\nwe can add this\nnew agentic layer and\nthen we can augment\nand automate a lot\nof these processes, right?\nThat's our branch functionality.\nAnd then we have\nour build plan. So\nlet's go into build\nplan. And let me\nshow you what one\nof these methods actually\nlooks like. We're building\na template request, right?\nSo we have our\nagent name, the slash\ncommand, right? And remember\nthe slash command activates\nthe right prompt and\nthen the arguments that\ngo into the prompt,\nright? Specifying the model\nwhen you run this\nand when you set\nup your ADWs, I\nhighly recommend for your\nbuild and implement steps,\nright? You build and\nimplement, you use the\nmost powerful model you\ncan just for presentation\nsake. I'm using Sonnet\njust cause it's going\nto be a little\nfaster, but you're going\nto want to throw\ntop models into the\nmost complex steps, which\nare going to be\nyour plan and your\nbuild step. Build plan,\nyou know, we're just\ngoing to kick off\nthis slash command, run\nsome debugging logs, and\nthen we're going to\nexecute it, okay? And\nall the way at\nthe bottom here, the\nexecute step is, of\ncourse, in our agent\nmodule, which is going\nto build the prompt,\nlog the prompt, and\nthen run the code\nusing Claude Code in\nprogrammable mode. All right.\nThis is why this\nis so important, right?\nWe're kicking off cloud\ncode right here like\nthis. Be sure to\nread through this. It\nis running dangerously, but\nbecause it's in its\nown environment, this is\ngoing to be safe,\nright? And the key\nidea here is this\nis, this is the\nvalue of programmable mode.\nThis is why it's\nso powerful. It lets\nus use Claude Code\nas a new agentic\ncoding primitive, where we\ncan call our agent\nwith any prompt and\nany step of our\nworkflow that we need\nto automate engineering work.\nAll right. So this\nis all here. This\nis going to set\nup a great base\nframework for you to\nunderstand ADWs and build\nthem into your own\ncodebases. All right.\nSo that's what this\nis doing. There's going\nto call the build\nprompt. There's going to\ncall the write slash\ncommand with the planner\nagent. And after that,\nright, we just continue\nthe flow. We then\ntap into whatever next\nstep we want, right?\nSo if we scroll\ndown from here, we're\nchecking errors. We're continuously\nupdating on what the\nissue is on what's\ncoming next. And we're\nmaking it observable. A\ncouple really key pieces\nhere that we're going\nto look at in\nupcoming lessons. We have\nour system reporting individual\nlog files on a\nCloud Code session ID\nbasis. So we can\ncome in to this\nsystem, this device, and\nreally understand what's going\non here at a\nvery, very detailed level.\nWe activated this thanks\nto Cloud Code hooks,\nbut there are many\nmechanisms to tap into\nthis functionality. So that's\none mechanism in which\nwe can observe and\nreview. We also have\nagents that run on\na AI developer workflow\nbasis. This workflow has\nunits as you progress\nthrough each lesson. But\nthis is important. ADWs\nlet us create a\nnew agentic layer around\nour codebase that\ntell our agents how\nto operate and perform\nreal engineering work. Okay.\nIf we look here,\nthis workflow is complete.\nThere's the PR. We\ncan get out of\nthis. Look at this\nissue here. You can\nsee this entire workflow\ntook about 17 or\nso minutes. And there\nit is, right? So\nwe now have JSON-L\nsupport. We can hop\nin here, review this.\nThere's all the files\nchanged. It's all getting\nreported based on our\nPR review prompt. All\nright, this looks great.\nIt handles all these\nkey features. Comprehensive test\ncoverage, love to see\nthat. And then we\ncan, of course, you\nknow, review all this\ncode, see the files\nchanged, see everything that's\nchanged. There's the front\nend UI updated. Here\nis some sample data,\njust like we asked\nfor in our tests,\ncomplex data, sample data,\nand on and on\nand on, all right?\nAnd of course, very\nimportantly, here's the plan.\nright? The planner created\nthe plan and outputted\na concrete asset that\nwe can use to\nunderstand what our implementer\nwill do. This is\nreally, really important. This\nlets you improve, right?\nIt's not enough to\njust run a random\nad hoc prompt because\nhow will you know\nhow to improve that?\nAnd more importantly, how\nwill your agents know?\nhow to improve that.\nYou know, we can\nlook through this entire\nplan. You can see\nit's very comprehensive. Our\nagent created a 170\nline plan and then\nour implementer went and\nbuilt this out. Okay.\nSo we have an\nopinionated plan build workflow\nthat fits our code\nbase for building features.\nOkay. So, you know,\nwe can hop into\nthis codebase here.\nand see how this\nactually turned out because\nour agent was updating\nin this environment. You\ncan see we're still\non that feature. So\nwhat I'll do here\nis just boot up\nthe client and server\nagain with all this\nupdated code here. And\nthen let's just see\nwhat it looks like,\nright? Let's open up\nChrome. Let's go to\nour natural language interface\nand refresh. You can\nsee it's added a\ncouple different test items.\nIt was operating right\non this SQL database.\nSo that looks good.\nThere are things there.\nLet's do a quick\nregression test, select users,\ndescending, sign update, Let's\nfire that off. We\nshould get our same\nprompt. There we go.\nNothing different there. Order\nby descending looks great.\nAnd now let's go\nahead and try to\nupload some. Okay, so\nlet's check this out.\nOur UI got updated\nCSV, JSON or JSON\nL. That looks great.\nWe have a new\noption. We can select\nevent analytics. That looks\ngood. Let's go ahead\nand drag and drop\nthis in. On that\nPR, it told us\nwhere exactly that was.\nLet's drag and drop\nin that sample data.\nThis is gonna be\nin test assets. So\nwe can quickly just\nfind that app server\ntests assets. Let's open\nand finder assets. Here\nwe go. Browser drag\nand drop simple JSON\ndata here. Scroll down.\nLet's see where our\nsimple data is. Okay.\nSo that's here. I\nthink that was there\nbefore. So I'm just\ngoing to go ahead\nand just delete this\nand I'll delete complex\ndata as well. And\nthen I'll redirect and\ndrop this in, right?\nWe wanna make sure\nthis is a fresh\nupload. Let me go\nahead and hide this\nso we can see\neverything below. Upload, sample\ndata, JSONL, drag and\ndrop. There it is,\nsample data from a\nJSONL file. And you\ncan see we have\nthat exact same naming\nconvention as specified. This\nwas a feature that\nan engineer may have\ntaken up, may have\npicked up themselves, and\nit was completely unnecessary,\nokay? I can guarantee\nyou right now, you\nor an engineer on\nyour team, you're working\non things, you can\nfully automate by creating\nan agentic layer around\nyour codebase that\nis driven by the\nfour elements of AFK\nagents. Right. And doing\nall this will help\nyou stay out the\nloop. There is no\nreason to do engineering\nwork like this. And\nthis trend will continue.\nOK, this is not\nspecific to this code\nbase. Yes. Right now\nit is small, but\nit doesn't matter. The\nsize only matters so\nmuch. OK. And every\ntime you miss something,\nwhat do you do?\nYou don't fix the\nissue. you fix the\nsystem that caused the\nissue, right? You fix\nyour templates, you fix\nyour ADW. Okay, so\nanyway, let's finish testing\nthis. Sample data, all\nrows, age between 10\nand 50. Okay, so\njust a random query\nto just showcase that\nall of our data\nis here. This feature\nwas created in one\nshot. We now have\nJSON L support. So\nthat's there. That was\ncreated on this branch,\non this machine. We\nset up the four\nelements and this happened\nend to end. And\nI just wanna stress\nthis one more time.\nIt doesn't matter if\nyou use GitHub issues,\nif you like JIRA\ntasks, Notion boards, whatever\nyou wanna use. The\nkey is that these\nfour elements are always\nthere and you want\nto build systems that\nbuild the system for\nyou. That's the key\nhere. That's the key\npiece of information from\nthis lesson before we\npush this to the\nnext level. And what\ndedicated environment. I highly,\nhighly recommend you do\nthis. You want a\ndedicated environment. that your\nagent can run in\non its own. This\nway you can create\na GitHub issue anywhere\nyou want, or you\ncan fire off a\nprompt input that hits\na trigger that then\nkicks off your agentic\nworkflows no matter where\nthey're running. All right,\nthis is super key,\nsuper important. We have\ntwo units of engineering\nwork that happened agentically\nfor our codebase,\nfor the TAC4 code\nbase. That's the key,\nADWs and the prompt\ntemplates you build out\nfor your codebase,\nthey solve classes of\nproblems that you no\nlonger have to solve.\nYou don't immediately start\nwith top tier agent\ncode and KPIs. You're\ngonna run some of\nthese, you're gonna run\nsome ADWs, you're gonna\nrun some prompts, some\ntemplates that don't fully\nsolve the problem. Then\nyou'll spend some time,\nyou'll invest in your\ntemplates, and then you'll\ncompose them into your\nADWs and you'll improve.\nThis is the new\nlayer, the compositional unit\nthat I highly, highly\nrecommend that you focus\non now. Don't sit\nand prompt back and\nforth build up these\nworkflows, your agent can\nsolve many, many problems\nthat you and others\nare still wasting your\ntime building. Okay. I\nwant to be really\nblunt here. I want\nto help you get\nahead. And that means\naddressing the faults of\nwhere we currently are.\nAll right. In loop\nagentic coding is great\nfor experimentation. It's great\nfor exploring new territory\nand it's great for\nvery, very hard, very\nspecific problems. Okay. But\nlet's be real. Most\nof engineering is not\nthat. So, If you\ninvest a little bit\nof time here, setting\nup your reusable prompts,\nright? Your templates, your\nmeta prompts, and then\ncreating some ADWs that\nonce you set these\nup, they're just there,\nright? You know, for\nthis codebase, this\njust solves entire classes\nof engineering problems now\nmoving forward, right? You\njust solve that. these\ntypes of problems, they're\njust solved. All I\nhave to do is\nwrite the prompt, the\nhigh level prompt, not\neven the plan, okay?\nSo I hope you\ncan see things coming\ntogether here. There's a\nlot to dissect, but\nthe idea here is\nsimple. Build a new\nagentic layer in your\ncodebase so your\nagents can run and\nship engineering work based\non your engineering problems,\nbased on your code\nbase, all right? By\ndoing this, by dedicating\nand focusing really hard\non these, you know,\ntwo essential directories, .clawed\ncommands, aka wherever your\nprompts are stored and\nADWs also known as\ncompositional workflows are stored,\nright? Your agentic workflows,\nyour agentic pipelines, your\nADWs, AI developer workflows.\nSo many names for\nthe same thing, right?\nYou wanna focus on\nthese elements and you\nwanna create this outer\nlayer to automate the\ndifferent classes of software\nengineering problems that you\nhave. It makes you\nadd logging, add observability.\nYou wanna make it\neasy to understand where\nand how things are\nhappening, right? We can\nhop into the issue\nand we can see\nthis agent completed its\nwork. Then we can\nreview to make sure\nthat it is actually\ndone. You want to\nset up the four\nelements of AFK agents,\nprompt input, trigger, environment,\nreview system. And this\nenables you when you\nput these things together,\nyou can stay out\nthe loop. For example,\nthis is one workflow,\none Outloop system I\nhave set up. This\ndevice now is always\nrunning for me. If\nI hop into this\nbox, and I kick\nthis trigger off again,\nthis codebase is\nalways listening to whatever\nweb hook I have\nset up for any\ncodebase now, and\nit will just start\nsolving the problem. After\nthe upfront, you know,\ninstall, right? And you\ncan encode all the\ninstallation into a slash\ninstall command, right? After\nyou get the setup,\nyou have an agent\noperating its own environment.\nYou can call using\nan out loop system.\nThis is massive impact.\nI recommend you take\naction on this now.\nLike don't wait, the\nROI here is insane.\nI want you to\nget to the aha\nlight bulb moment you'll\nget when you run\none of these end\nto end, all right?\nStart with something simple,\nyou know, get everything\nconfigured and fire off\na chore. What you\nwanna do is understand\nhow controllable this is.\nYes, it's true. There\nare cloud-based tools that\ndo this workflow, but\nthat's not exactly true.\nThese tools are not\nrunning your templates, right?\nThey're not running your\nprompts. They're not built\nto solve your problems,\nright? Your classes of\nproblems that every engineer\nfaces. So invest in\nthis. This is a\ncritical, critical lesson, right?\nStart with great defaults.\nYou know, for your\nprompt input, I highly\nrecommend you just go\nwith GitHub issues for\nyour review system at\nthe end, GitHub PRs,\nand then your trigger\nand your environment. Just\nstart setting this up\nlocally and then offload\nit to another device,\nright? You want to\nget to this point\nwhere you start with\nlow hanging fruit, you\nknow, build up trust\nand your ADW and\nout the loop. Focus\non this new agentic\nlayer. this new outer\nlayer on your code\nbase so that your\nproduct ships itself. We\nnow have a tactic\nthat guides us toward\nbuilding autonomous systems. When\nyou stay out the\nloop, you prioritize agentic\ncoding. We solve problem\nclasses and we build\na system that builds\na system, right? Our\nsystems, this agentic layer\nis solving the detailed\nproblems while we're teaching\nit how to. In\na lot of ways,\nwe're automating the central\nunits of the software\ndeveloper lifecycle so that\nwe can focus on\nwhat we want, the\nplanning and the reviewing.\nOkay. By templating your\nengineering, we increase our\nplanning velocity by encoding\nsolutions to classes of\nproblems into the outer\nlayer of our code\nbase, the agentic layer.\nThis is great, but\nthere is a massive\nissue. These workflows, although\npowerful, they require lots\nand lots of reviewing\nat some level. We'll\nalways need to review,\nbut wouldn't it be\ngreat if we could\nincrease our review velocity\nas we scale our\nplanning and building velocity\nwith our agents. In\nthe next lesson, we're\ngoing to do exactly\nthat. We're going to\nclose the loops. We're\ngoing to give our\nagents multiple leverage points\nof agentic coding needed\nto validate their own\nwork. We're going to\nteach them how to\ndo this on multiple\ndimensions because what's better\nthan one test? Yes,\ntwo, three or 10.\nAll right. So in\nlesson five, we teach\nour agents how to\ntest and validate not\njust back end work,\nnot just scripts, but\nfront end and all\ntypes of engineering. By\ndoing this, increase our\nreview velocity by teaching\nour agents how to\nvalidate their work great\njob here you're making\na ton of progress\nyou are halfway through\nTactical Agentic Coding take\nsome time to digest\nthis information there's a\nlot here this lesson\nis pivotal your ability\nto internalize lesson three\nand four will decide\nif you come out\non top here template\nand stay out the\nloop i'll see you\nin lesson five where\nwe increase the reliability\nof your agents by\ndrastically cutting down the\ntime you and your\nteam need to spend\nreviewing and fixing agent\noutputs. I'll see you\nin lesson five."
}